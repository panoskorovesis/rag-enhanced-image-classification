{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-28T17:18:41.500632Z",
     "iopub.status.busy": "2025-01-28T17:18:41.500241Z",
     "iopub.status.idle": "2025-01-28T17:18:57.858939Z",
     "shell.execute_reply": "2025-01-28T17:18:57.857700Z",
     "shell.execute_reply.started": "2025-01-28T17:18:41.500599Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (1.0.14)\n",
      "Requirement already satisfied: torch in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from timm) (2.6.0)\n",
      "Requirement already satisfied: torchvision in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from timm) (0.21.0)\n",
      "Requirement already satisfied: pyyaml in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from timm) (0.28.1)\n",
      "Requirement already satisfied: safetensors in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from timm) (0.5.2)\n",
      "Requirement already satisfied: filelock in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from huggingface_hub->timm) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from huggingface_hub->timm) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: requests in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torchvision->timm) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from torchvision->timm) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (2024.12.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panos/WSL_projects/rag-enhanced-image-classification/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# First make sure to install timm\n",
    "!pip install timm\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import timm\n",
    "import torchvision\n",
    "from sklearn.metrics import classification_report\n",
    "from pprint import pprint\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Selection\n",
    "\n",
    "We will opt for gpu, if it's available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset\n",
    "\n",
    "We can use CIFAR10 or CIFAR100 as our dataset. Since both are really common datasets we will use the `torchvision.datasets` class to load them.\n",
    "\n",
    "To select the dataset, modify the `use_CIFAR10` boolean variable accordingly.\n",
    "\n",
    "We also apply some basic __preprocessing__:\n",
    "\n",
    "1. Normalize the dataset by subtracting the _mean_ and dividing with the _std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_mean_std(dataset):\n",
    "    \"\"\"Compute mean and standard deviation of a dataset dynamically.\"\"\"\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    \n",
    "    for images, _ in loader:\n",
    "        mean += images.mean(dim=[0, 2, 3])\n",
    "        std += images.std(dim=[0, 2, 3])\n",
    "    \n",
    "    mean /= len(loader)\n",
    "    std /= len(loader)\n",
    "    \n",
    "    return mean, std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_directory = \"../../../cifar-10-batches-py-for-pytorch\"\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((224, 224))\n",
    "])\n",
    "\n",
    "cifar10_dataset = torchvision.datasets.CIFAR10(root=dataset_directory, train=True, download=True, transform=transform)\n",
    "mean_cifar100, std_cifar100 = compute_mean_std(cifar10_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.5070, 0.4865, 0.4408])\n",
      "Std: tensor([0.2613, 0.2503, 0.2703])\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean: {mean_cifar100}')\n",
    "print(f'Std: {std_cifar100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:19:48.873522Z",
     "iopub.status.busy": "2025-01-28T17:19:48.873015Z",
     "iopub.status.idle": "2025-01-28T17:19:56.850337Z",
     "shell.execute_reply": "2025-01-28T17:19:56.849200Z",
     "shell.execute_reply.started": "2025-01-28T17:19:48.873469Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded. Total images: 50000\n",
      "Train images: 45000\n",
      "Validation images: 5000\n",
      "Test images: 10000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "use_CIFAR10 = True\n",
    "\n",
    "# Get the precomputed mean and std\n",
    "# Those are needed to normalize the dataset\n",
    "# NOTE: To calculate the mean and std we have to \n",
    "# 1. calculate the sum for each channel\n",
    "# 2. implement mean and variance formulas\n",
    "if use_CIFAR10:\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std = (0.2023, 0.1994, 0.2010)\n",
    "else:\n",
    "    # raise NotImplementedError(\"Please compute mean, std for CIFAR100\")\n",
    "    mean = (0.5070, 0.4865, 0.4408)\n",
    "    std = (0.2613, 0.2503, 0.2703)\n",
    "\n",
    "# dataset directory remains the same for both cases\n",
    "dataset_directory = \"src/development/output_data\"\n",
    "\n",
    "# the transformation also remains the same\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# download the dataset\n",
    "if use_CIFAR10:\n",
    "    cifar_dataset = torchvision.datasets.CIFAR10(root=dataset_directory, train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root=dataset_directory, train=False, download=True, transform=transform)\n",
    "else:\n",
    "    cifar_dataset = torchvision.datasets.CIFAR100(root=dataset_directory, train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR100(root=dataset_directory, train=False, download=True, transform=transform)\n",
    "\n",
    "print(f'Dataset downloaded. Total images: {len(cifar_dataset)}')\n",
    "\n",
    "# Split the dataset into train / valildation sets\n",
    "train_size = int(0.9 * len(cifar_dataset))\n",
    "val_size = len(cifar_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(cifar_dataset, [train_size, val_size])\n",
    "\n",
    "# set the batch size to 64\n",
    "batch_size = 64\n",
    "\n",
    "# Create some dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f'Train images: {train_size}')\n",
    "print(f'Validation images: {val_size}')\n",
    "print(f'Test images: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Methods\n",
    "\n",
    "Bellow we have created some methods to make the code simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common List Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:59:25.208551Z",
     "iopub.status.busy": "2025-01-28T17:59:25.208156Z",
     "iopub.status.idle": "2025-01-28T17:59:25.214077Z",
     "shell.execute_reply": "2025-01-28T17:59:25.212753Z",
     "shell.execute_reply.started": "2025-01-28T17:59:25.208506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_common(lst):\n",
    "    data = Counter(lst)\n",
    "    return max(lst, key=data.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CLS Token\n",
    "\n",
    "By taking a look at the [documentation](https://huggingface.co/docs/timm/en/feature_extraction) for the timm library and specifically the __Feature Extraction__ section we can see that in order to get the __last hidden state__ of the model we have to use the `forward_features` method.\n",
    "\n",
    "Specifically, this method returns the patch embeddings at the last hidden state, __before pooling is applied__. The return vector is of shape\n",
    "\n",
    "```\n",
    "(batch_size, num_patches + 1, hidden_size)\n",
    "```\n",
    "\n",
    "The __CLS Token__ is by design the __first of the patch embeddings__\n",
    "\n",
    "For example to get the CLS Token of the first image in the batch we would have to do:\n",
    "\n",
    "```py\n",
    "model_output[0, 0, :]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_cls_token(model: timm.models.vision_transformer.VisionTransformer, images: torch.Tensor) -> np.array:\n",
    "    # get the last hidden state\n",
    "    output = model.forward_features(images)\n",
    "\n",
    "    # for each image get the cls token\n",
    "    # make sure to convert each tensor to numpy\n",
    "    cls_tokens = output[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    return cls_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Patch Embeddings\n",
    "\n",
    "By taking a look at the [documentation](https://huggingface.co/docs/timm/en/feature_extraction) for the timm library and specifically the __Feature Extraction__ section we can see that in order to get the __last hidden state__ of the model we have to use the `forward_features` method.\n",
    "\n",
    "Specifically, this method returns the patch embeddings at the last hidden state, __before pooling is applied__. The return vector is of shape\n",
    "\n",
    "```\n",
    "(batch_size, num_patches + 1, hidden_size)\n",
    "```\n",
    "\n",
    "We want to get all the patch embeddings with an option to also include the cls.\n",
    "\n",
    "As such, to get everything except the cls we will have to do\n",
    "```py\n",
    "cls_tokens = output[:, 1:, :].cpu().numpy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:02:39.259845Z",
     "iopub.status.busy": "2025-01-28T18:02:39.259413Z",
     "iopub.status.idle": "2025-01-28T18:02:39.266165Z",
     "shell.execute_reply": "2025-01-28T18:02:39.264846Z",
     "shell.execute_reply.started": "2025-01-28T18:02:39.259808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_patch_embeddings(model: timm.models.vision_transformer.VisionTransformer, images: torch.Tensor, include_cls: bool = False) -> np.array:\n",
    "    # get the last hidden state\n",
    "    output = model.forward_features(images)\n",
    "\n",
    "    # If we dont want the cls we have to skip the first line\n",
    "    if not include_cls:\n",
    "        return output[:, 1:, :].cpu().numpy()\n",
    "    # else return the whole hidden state\n",
    "    else:\n",
    "        return output[:, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract CLS Tokens for all images in a DataLoader\n",
    "\n",
    "This method uses the `get_cls_token` method above to extract all cls tokens from a given dataloader.\n",
    "\n",
    "For each image we will also need:\n",
    "    \n",
    "    1. it's original position (?)\n",
    "    2. the label\n",
    "\n",
    "The method returns __a dictionary__ with:\n",
    "1. __key__: The original position of the image\n",
    "2. __value__: A dictionary with `cls_token` and `label` keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:20:50.334487Z",
     "iopub.status.busy": "2025-01-28T17:20:50.334115Z",
     "iopub.status.idle": "2025-01-28T17:20:50.341449Z",
     "shell.execute_reply": "2025-01-28T17:20:50.339732Z",
     "shell.execute_reply.started": "2025-01-28T17:20:50.334461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_dataset_cls_tokens(model: timm.models.vision_transformer.VisionTransformer, loader: torch.utils.data.dataloader.DataLoader\n",
    "):\n",
    "\n",
    "    cls_tokens = []\n",
    "    cls_labels = []\n",
    "\n",
    "    for idx, (images, labels) in tqdm(enumerate(loader), desc=\"Calculating CLS Tokens\", total=len(loader)):\n",
    "        # move to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # this returns a numpy array with shape\n",
    "        # (batch_size, hidden_size)\n",
    "        tokens = get_cls_token(model=model, images=images)\n",
    "\n",
    "        # For each image in the batch\n",
    "        for idx in range(tokens.shape[0]):\n",
    "            cls_tokens.append(tokens[idx, :])\n",
    "            cls_labels.append(labels[idx])\n",
    "\n",
    "    return cls_tokens, cls_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Patch Embeddings for all images in DataLoader\n",
    "\n",
    "This method uses the `get_patch_embeddings` method above to extract all patch embeddings from a given dataloder.\n",
    "\n",
    "__NOTES__:\n",
    "- Each image has multiple patch embeddings.\n",
    "- Each patch embedding will have the shame label as it's source image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:19:19.446837Z",
     "iopub.status.busy": "2025-01-28T18:19:19.446360Z",
     "iopub.status.idle": "2025-01-28T18:19:19.456692Z",
     "shell.execute_reply": "2025-01-28T18:19:19.455208Z",
     "shell.execute_reply.started": "2025-01-28T18:19:19.446807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_dataset_patch_embeddings(model: timm.models.vision_transformer.VisionTransformer, loader: torch.utils.data.dataloader.DataLoader, include_cls: bool = False, is_test: bool = False\n",
    "):\n",
    "\n",
    "    patch_embeddings = []\n",
    "    patch_labels = []\n",
    "\n",
    "    for cnt, (images, labels) in tqdm(enumerate(loader), desc=\"Calculating Patch Embeddings\", total=len(loader)):\n",
    "\n",
    "        # move to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # this returns a numpy array with shape\n",
    "        # (batch_size, num_patches, hidden_size)\n",
    "        embs = get_patch_embeddings(model=model, images=images, include_cls=include_cls)\n",
    "\n",
    "        # For each image in the batch\n",
    "        for idx in range(embs.shape[0]):\n",
    "            # If we are not calculating for the test, we simply need a label for each patch\n",
    "            if not is_test:\n",
    "                # For each patch\n",
    "                for p_idx in range(embs.shape[1]):\n",
    "                    patch_embeddings.append(embs[idx, p_idx, :])\n",
    "                    patch_labels.append(labels[idx])\n",
    "            # Else we want to keep track of patches that belong in a single image\n",
    "            else:\n",
    "                image_embs = []\n",
    "                image_labels = []\n",
    "                for p_idx in range(embs.shape[1]):\n",
    "                    image_embs.append(embs[idx, p_idx, :])\n",
    "                    image_labels.append(labels[idx])\n",
    "\n",
    "                # Now add to the original lists\n",
    "                patch_embeddings.append(image_embs)\n",
    "                patch_labels.append(image_labels)\n",
    "\n",
    "        if not is_test and cnt == 70:\n",
    "            break\n",
    "    \n",
    "    return patch_embeddings, patch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the VIT model\n",
    "\n",
    "To load the model we will use the `timm` library.\n",
    "\n",
    "We could also use the `transformers` library and more specific the `ViTForImageClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:19:33.057570Z",
     "iopub.status.busy": "2025-01-28T17:19:33.057233Z",
     "iopub.status.idle": "2025-01-28T17:19:33.815386Z",
     "shell.execute_reply": "2025-01-28T17:19:33.814148Z",
     "shell.execute_reply.started": "2025-01-28T17:19:33.057544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    \"vit_tiny_patch16_224\",  # Pre-trained ViT-Tiny on ImageNet-1k\n",
    "    pretrained=True,        # Load pre-trained weights\n",
    "    num_classes=10          # Adapt classifier head to CIFAR-10 (10 classes)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# We dont want to train here so we can freeze all the layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CLS Tokens for the Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:45:59.666182Z",
     "iopub.status.busy": "2025-01-24T17:45:59.665828Z",
     "iopub.status.idle": "2025-01-24T18:09:30.103317Z",
     "shell.execute_reply": "2025-01-24T18:09:30.102260Z",
     "shell.execute_reply.started": "2025-01-24T17:45:59.666156Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating CLS Tokens:   0%|          | 0/704 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating CLS Tokens: 100%|██████████| 704/704 [03:42<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "train_cls_tokens, train_labels = get_dataset_cls_tokens(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CLS Tokens for the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating CLS Tokens: 100%|██████████| 157/157 [00:52<00:00,  3.00it/s]\n"
     ]
    }
   ],
   "source": [
    "test_cls_tokens, test_labels = get_dataset_cls_tokens(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Patch Embeddings for the Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:20:14.422847Z",
     "iopub.status.busy": "2025-01-28T18:20:14.422387Z",
     "iopub.status.idle": "2025-01-28T18:22:11.593721Z",
     "shell.execute_reply": "2025-01-28T18:22:11.592298Z",
     "shell.execute_reply.started": "2025-01-28T18:20:14.422819Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Patch Embeddings:   0%|          | 0/704 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Patch Embeddings:  10%|▉         | 70/704 [00:24<03:38,  2.91it/s]\n"
     ]
    }
   ],
   "source": [
    "patch_embeddings, patch_labels = get_dataset_patch_embeddings(model=model, loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:22:37.506656Z",
     "iopub.status.busy": "2025-01-28T18:22:37.506175Z",
     "iopub.status.idle": "2025-01-28T18:22:37.514456Z",
     "shell.execute_reply": "2025-01-28T18:22:37.513003Z",
     "shell.execute_reply.started": "2025-01-28T18:22:37.506616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patch embeddings in memory: 890624\n",
      "Total images in memory: 4544.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Total patch embeddings in memory: {len(patch_embeddings)}')\n",
    "print(f'Total images in memory: {len(patch_embeddings) / 196}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Patch Embeddings for the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:22:45.100886Z",
     "iopub.status.busy": "2025-01-28T18:22:45.100314Z",
     "iopub.status.idle": "2025-01-28T18:24:44.718326Z",
     "shell.execute_reply": "2025-01-28T18:24:44.717152Z",
     "shell.execute_reply.started": "2025-01-28T18:22:45.100850Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Patch Embeddings: 100%|██████████| 157/157 [00:46<00:00,  3.36it/s]\n"
     ]
    }
   ],
   "source": [
    "test_patch_embeddings, test_patch_labels = get_dataset_patch_embeddings(model=model, loader=test_loader, is_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Method: Get Neighbors and Labels\n",
    "\n",
    "This method will be used by other parts of the project. It returns two items:\n",
    "\n",
    "1. `cls_tokens`: An array of shape (num_test, k): Each row contains the cls_token that corresponds the the neighbor.\n",
    "2. `labels`: An array of shape (num_test, k): Each row contains the labels of those top-k images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:24:44.720831Z",
     "iopub.status.busy": "2025-01-28T18:24:44.720493Z",
     "iopub.status.idle": "2025-01-28T18:24:44.730307Z",
     "shell.execute_reply": "2025-01-28T18:24:44.728984Z",
     "shell.execute_reply.started": "2025-01-28T18:24:44.720801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def get_neighbors_and_labels(distance: str, train_data: np.array, train_labels: list, test_data: list, top_k: int = 5):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "    \n",
    "    print(\"Will set labels to cpu\")\n",
    "    clean_labels = []\n",
    "    for label in tqdm(\n",
    "        train_labels, total=len(train_labels), desc=\"Converting labels to cpu\"\n",
    "    ):\n",
    "        clean_labels.append(label.to(\"cpu\"))\n",
    "\n",
    "    # Create a numpy array from the list\n",
    "    print(f\"Total train images: {len(train_data)}\")\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    clean_labels = np.stack(clean_labels, axis=0)\n",
    "    print(f\"Train shape: {train_data.shape}\")\n",
    "    print(f\"Train labels shape: {clean_labels.shape}\")\n",
    "    \n",
    "    # Fit with the train set\n",
    "    knn.fit(train_data)\n",
    "    \n",
    "    # Create a numpy array for the test images\n",
    "    print(f'Total test images: {len(test_data)}')\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f'Test shape: {test_data.shape}')\n",
    "    \n",
    "    # Apply the knn\n",
    "    distances, indexes = knn.kneighbors(test_data, return_distance=True)\n",
    "    \n",
    "    print(f'Distances: {distances.shape}')\n",
    "    print(f'Indexes: {distances.shape}')\n",
    "    \n",
    "    neighbor_labels = []\n",
    "    neighbor_cls_tokens = []\n",
    "    # Gather the final labels\n",
    "    # And the cls_tokens\n",
    "    # For each test image\n",
    "    for i in tqdm(range(indexes.shape[0]), desc='Gathering results'):\n",
    "        # Get the classes of the top_k\n",
    "        classes = clean_labels[indexes[i]]\n",
    "        neighbor_labels.append(classes)\n",
    "        \n",
    "        # Get the cls_tokens of the top_k\n",
    "        cls_tokens = train_data[indexes[i]]\n",
    "        neighbor_cls_tokens.append(cls_tokens)\n",
    "    \n",
    "    # finally convert the the labels to array\n",
    "    neighbor_labels = np.stack(neighbor_labels, axis=0)\n",
    "    # Do the same for the cls\n",
    "    neighbor_cls_tokens = np.stack(neighbor_cls_tokens, axis=0)\n",
    "    \n",
    "    return neighbor_cls_tokens, neighbor_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Method: Get Neighbor Distances and Labels\n",
    "\n",
    "This method will be used by other parts of the project. It returns two items:\n",
    "\n",
    "1. `distances`: An array of shape (num_test, k): Each row contains the distances of the top-k similar images from the train set.\n",
    "2. `labels`: An array of shape (num_test, k): Each row contains the labels of those top-k images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:24:44.732537Z",
     "iopub.status.busy": "2025-01-28T18:24:44.732140Z",
     "iopub.status.idle": "2025-01-28T18:24:44.759106Z",
     "shell.execute_reply": "2025-01-28T18:24:44.757825Z",
     "shell.execute_reply.started": "2025-01-28T18:24:44.732509Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def get_neighbors_distances_and_labels(distance: str, train_data: list, train_labels: np.array, test_data: np.array, top_k: int = 5):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "    \n",
    "    # Create a numpy array from the list\n",
    "    print(f'Total train images: {len(train_data)}')\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    print(f'Train shape: {train_data.shape}')\n",
    "    \n",
    "    # Fit with the train set\n",
    "    knn.fit(train_data)\n",
    "    \n",
    "    # Create a numpy array for the test images\n",
    "    print(f'Total test images: {len(test_data)}')\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f'Test shape: {test_data.shape}')\n",
    "    \n",
    "    # Apply the knn\n",
    "    distances, indexes = knn.kneighbors(test_data, return_distance=True)\n",
    "    \n",
    "    print(f'Distances: {distances.shape}')\n",
    "    print(f'Indexes: {distances.shape}')\n",
    "    \n",
    "    neighbor_labels = []\n",
    "    # Gather the final labels\n",
    "    # For each test image\n",
    "    for i in tqdm(range(indexes.shape[0]), desc='Gathering results'):\n",
    "        # Get the classes of the top_k\n",
    "        classes = train_labels[indexes[i]]\n",
    "        neighbor_labels.append(classes)\n",
    "    \n",
    "    # finally convert the the labels to array\n",
    "    neighbor_labels = np.stack(neighbor_labels, axis=0)\n",
    "\n",
    "    return distances, neighbor_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute Force KNN - WITHOUT Test Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CLS Embeddings\n",
    "\n",
    "In the following cells we will try to find the labels from the test images by doing the following:\n",
    "\n",
    "1) Use the `ViT` model to extract the cls_token for the test image\n",
    "2) Find the `topK` similar cls_tokens from the train dataset\n",
    "3) Assign the `y_pred` to the majority class from the KNN\n",
    "\n",
    "__This method will act as our baseline__ as it does not require a finetuned Visual Transformer.\n",
    "\n",
    "The method bellow implements the brute force KNN, using the CLS embeddings for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:24:44.761321Z",
     "iopub.status.busy": "2025-01-28T18:24:44.760929Z",
     "iopub.status.idle": "2025-01-28T18:24:44.785587Z",
     "shell.execute_reply": "2025-01-28T18:24:44.784242Z",
     "shell.execute_reply.started": "2025-01-28T18:24:44.761293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def brute_force_knn(distance: str, train_data: np.array, train_labels: np.array, test_data: np.array, top_k: int = 5):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "    \n",
    "    # Create a numpy array from the list\n",
    "    print(f'Total train images: {len(train_data)}')\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    print(f'Train shape: {train_data.shape}')\n",
    "    \n",
    "    # Fit with the train set\n",
    "    knn.fit(train_data)\n",
    "    \n",
    "    # Create a numpy array for the test images\n",
    "    print(f'Total test images: {len(test_data)}')\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f'Test shape: {test_data.shape}')\n",
    "    \n",
    "    # Apply the knn\n",
    "    distances, indexes = knn.kneighbors(test_data, return_distance=True)\n",
    "    \n",
    "    print(f'Distances: {distances.shape}')\n",
    "    print(f'Indexes: {distances.shape}')\n",
    "    \n",
    "    y_pred = []\n",
    "    # Gather the final y_pred\n",
    "    # For each test image\n",
    "    for i in tqdm(range(indexes.shape[0]), desc='Gathering results'):\n",
    "        # Get the classes of the top_k\n",
    "        classes = train_labels[indexes[i]]\n",
    "        # Select the majority as y_pred\n",
    "        y_pred.append(most_common(classes.tolist()))\n",
    "    \n",
    "    # finally convert the y_pred to array\n",
    "    y_pred = np.stack(y_pred, axis=0)\n",
    "\n",
    "    return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T22:50:43.849080Z",
     "iopub.status.busy": "2025-01-21T22:50:43.848583Z",
     "iopub.status.idle": "2025-01-21T22:51:52.473499Z",
     "shell.execute_reply": "2025-01-21T22:51:52.472238Z",
     "shell.execute_reply.started": "2025-01-21T22:50:43.849048Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 3)\n",
      "Indexes: (10000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 291172.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1000\n",
      "           1       0.70      0.72      0.71      1000\n",
      "           2       0.78      0.55      0.65      1000\n",
      "           3       0.56      0.49      0.52      1000\n",
      "           4       0.69      0.65      0.67      1000\n",
      "           5       0.61      0.60      0.61      1000\n",
      "           6       0.67      0.84      0.74      1000\n",
      "           7       0.70      0.77      0.73      1000\n",
      "           8       0.80      0.77      0.78      1000\n",
      "           9       0.66      0.76      0.71      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.69      0.69     10000\n",
      "weighted avg       0.69      0.69      0.69     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 5)\n",
      "Indexes: (10000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 277417.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.72      0.75      0.74      1000\n",
      "           2       0.84      0.55      0.66      1000\n",
      "           3       0.59      0.53      0.56      1000\n",
      "           4       0.71      0.67      0.69      1000\n",
      "           5       0.63      0.63      0.63      1000\n",
      "           6       0.66      0.86      0.75      1000\n",
      "           7       0.73      0.78      0.75      1000\n",
      "           8       0.80      0.79      0.79      1000\n",
      "           9       0.66      0.79      0.72      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.71     10000\n",
      "weighted avg       0.71      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 7)\n",
      "Indexes: (10000, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 260966.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1000\n",
      "           1       0.74      0.75      0.75      1000\n",
      "           2       0.85      0.53      0.65      1000\n",
      "           3       0.59      0.53      0.56      1000\n",
      "           4       0.73      0.68      0.70      1000\n",
      "           5       0.64      0.63      0.64      1000\n",
      "           6       0.66      0.88      0.75      1000\n",
      "           7       0.73      0.79      0.76      1000\n",
      "           8       0.82      0.79      0.81      1000\n",
      "           9       0.66      0.81      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 10)\n",
      "Indexes: (10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 235759.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1000\n",
      "           1       0.75      0.76      0.75      1000\n",
      "           2       0.86      0.51      0.64      1000\n",
      "           3       0.60      0.53      0.56      1000\n",
      "           4       0.73      0.68      0.70      1000\n",
      "           5       0.64      0.64      0.64      1000\n",
      "           6       0.64      0.88      0.74      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.82      0.78      0.80      1000\n",
      "           9       0.66      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 11)\n",
      "Indexes: (10000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 236574.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1000\n",
      "           1       0.75      0.76      0.75      1000\n",
      "           2       0.87      0.51      0.64      1000\n",
      "           3       0.60      0.53      0.56      1000\n",
      "           4       0.74      0.68      0.71      1000\n",
      "           5       0.64      0.65      0.64      1000\n",
      "           6       0.64      0.88      0.74      1000\n",
      "           7       0.73      0.78      0.76      1000\n",
      "           8       0.81      0.79      0.80      1000\n",
      "           9       0.66      0.81      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 222072.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1000\n",
      "           1       0.76      0.77      0.76      1000\n",
      "           2       0.88      0.51      0.64      1000\n",
      "           3       0.61      0.54      0.57      1000\n",
      "           4       0.74      0.68      0.71      1000\n",
      "           5       0.64      0.65      0.64      1000\n",
      "           6       0.64      0.89      0.75      1000\n",
      "           7       0.75      0.79      0.77      1000\n",
      "           8       0.83      0.80      0.81      1000\n",
      "           9       0.66      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.72     10000\n",
      "weighted avg       0.73      0.72      0.72     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 15)\n",
      "Indexes: (10000, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 210068.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1000\n",
      "           1       0.75      0.76      0.75      1000\n",
      "           2       0.88      0.50      0.64      1000\n",
      "           3       0.60      0.54      0.56      1000\n",
      "           4       0.73      0.68      0.70      1000\n",
      "           5       0.64      0.64      0.64      1000\n",
      "           6       0.64      0.89      0.75      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.83      0.79      0.81      1000\n",
      "           9       0.66      0.83      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.71      0.71     10000\n",
      "weighted avg       0.73      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 17)\n",
      "Indexes: (10000, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 195759.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1000\n",
      "           1       0.75      0.76      0.76      1000\n",
      "           2       0.90      0.49      0.64      1000\n",
      "           3       0.60      0.54      0.56      1000\n",
      "           4       0.74      0.67      0.70      1000\n",
      "           5       0.64      0.65      0.64      1000\n",
      "           6       0.64      0.89      0.74      1000\n",
      "           7       0.74      0.77      0.75      1000\n",
      "           8       0.82      0.79      0.80      1000\n",
      "           9       0.65      0.83      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.71      0.71     10000\n",
      "weighted avg       0.73      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 19)\n",
      "Indexes: (10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 201624.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.75      0.76      0.75      1000\n",
      "           2       0.91      0.49      0.64      1000\n",
      "           3       0.61      0.54      0.57      1000\n",
      "           4       0.74      0.67      0.70      1000\n",
      "           5       0.65      0.66      0.65      1000\n",
      "           6       0.64      0.89      0.74      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.82      0.79      0.81      1000\n",
      "           9       0.65      0.83      0.73      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.71     10000\n",
      "weighted avg       0.73      0.72      0.71     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [3, 5, 7, 10, 11, 13, 15, 17, 19]:\n",
    "    y_pred = brute_force_knn(distance=\"cosine\", train_data=train_cls_tokens, train_labels=train_labels, test_data=test_cls_tokens, top_k=k)\n",
    "    print('----------------------------')\n",
    "    print(f'COSINE - TOP_K: {k}')\n",
    "    print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Euclidian Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T22:53:26.531313Z",
     "iopub.status.busy": "2025-01-21T22:53:26.530905Z",
     "iopub.status.idle": "2025-01-21T22:54:02.469690Z",
     "shell.execute_reply": "2025-01-21T22:54:02.468656Z",
     "shell.execute_reply.started": "2025-01-21T22:53:26.531280Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 3)\n",
      "Indexes: (10000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 296849.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72      1000\n",
      "           1       0.71      0.70      0.71      1000\n",
      "           2       0.75      0.53      0.62      1000\n",
      "           3       0.53      0.49      0.51      1000\n",
      "           4       0.67      0.66      0.66      1000\n",
      "           5       0.60      0.59      0.59      1000\n",
      "           6       0.68      0.82      0.74      1000\n",
      "           7       0.71      0.77      0.74      1000\n",
      "           8       0.75      0.77      0.76      1000\n",
      "           9       0.66      0.74      0.70      1000\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.68      0.68      0.67     10000\n",
      "weighted avg       0.68      0.68      0.67     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 5)\n",
      "Indexes: (10000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 276519.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74      1000\n",
      "           1       0.73      0.72      0.73      1000\n",
      "           2       0.79      0.52      0.63      1000\n",
      "           3       0.56      0.50      0.53      1000\n",
      "           4       0.67      0.68      0.67      1000\n",
      "           5       0.62      0.61      0.61      1000\n",
      "           6       0.68      0.85      0.76      1000\n",
      "           7       0.73      0.75      0.74      1000\n",
      "           8       0.76      0.78      0.77      1000\n",
      "           9       0.66      0.77      0.71      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.69      0.69     10000\n",
      "weighted avg       0.69      0.69      0.69     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 7)\n",
      "Indexes: (10000, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 255840.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75      1000\n",
      "           1       0.75      0.73      0.74      1000\n",
      "           2       0.82      0.51      0.63      1000\n",
      "           3       0.57      0.52      0.54      1000\n",
      "           4       0.69      0.68      0.69      1000\n",
      "           5       0.63      0.62      0.62      1000\n",
      "           6       0.66      0.86      0.75      1000\n",
      "           7       0.73      0.76      0.75      1000\n",
      "           8       0.77      0.80      0.78      1000\n",
      "           9       0.66      0.80      0.73      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.70     10000\n",
      "weighted avg       0.71      0.70      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 10)\n",
      "Indexes: (10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 233521.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      1000\n",
      "           1       0.76      0.74      0.75      1000\n",
      "           2       0.84      0.51      0.63      1000\n",
      "           3       0.59      0.53      0.56      1000\n",
      "           4       0.68      0.69      0.69      1000\n",
      "           5       0.64      0.63      0.64      1000\n",
      "           6       0.67      0.87      0.76      1000\n",
      "           7       0.74      0.77      0.76      1000\n",
      "           8       0.78      0.79      0.79      1000\n",
      "           9       0.67      0.81      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 11)\n",
      "Indexes: (10000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 213484.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76      1000\n",
      "           1       0.76      0.74      0.75      1000\n",
      "           2       0.84      0.51      0.63      1000\n",
      "           3       0.58      0.52      0.55      1000\n",
      "           4       0.69      0.69      0.69      1000\n",
      "           5       0.63      0.62      0.63      1000\n",
      "           6       0.66      0.87      0.75      1000\n",
      "           7       0.74      0.77      0.75      1000\n",
      "           8       0.78      0.80      0.79      1000\n",
      "           9       0.67      0.82      0.74      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 209054.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76      1000\n",
      "           1       0.76      0.74      0.75      1000\n",
      "           2       0.85      0.49      0.62      1000\n",
      "           3       0.58      0.52      0.55      1000\n",
      "           4       0.70      0.69      0.70      1000\n",
      "           5       0.64      0.63      0.64      1000\n",
      "           6       0.65      0.88      0.75      1000\n",
      "           7       0.74      0.76      0.75      1000\n",
      "           8       0.77      0.79      0.78      1000\n",
      "           9       0.66      0.81      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 15)\n",
      "Indexes: (10000, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 207114.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.76      0.74      0.75      1000\n",
      "           2       0.86      0.48      0.62      1000\n",
      "           3       0.58      0.51      0.55      1000\n",
      "           4       0.70      0.70      0.70      1000\n",
      "           5       0.63      0.64      0.63      1000\n",
      "           6       0.65      0.88      0.75      1000\n",
      "           7       0.75      0.76      0.75      1000\n",
      "           8       0.77      0.81      0.79      1000\n",
      "           9       0.67      0.82      0.74      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.70     10000\n",
      "weighted avg       0.72      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 17)\n",
      "Indexes: (10000, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 193190.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75      1000\n",
      "           1       0.75      0.73      0.74      1000\n",
      "           2       0.87      0.48      0.61      1000\n",
      "           3       0.59      0.51      0.55      1000\n",
      "           4       0.69      0.68      0.69      1000\n",
      "           5       0.62      0.65      0.64      1000\n",
      "           6       0.65      0.88      0.75      1000\n",
      "           7       0.74      0.75      0.75      1000\n",
      "           8       0.77      0.81      0.79      1000\n",
      "           9       0.66      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.70     10000\n",
      "weighted avg       0.71      0.70      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 19)\n",
      "Indexes: (10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 191541.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.76      0.72      0.74      1000\n",
      "           2       0.87      0.48      0.62      1000\n",
      "           3       0.61      0.52      0.56      1000\n",
      "           4       0.70      0.68      0.69      1000\n",
      "           5       0.63      0.65      0.64      1000\n",
      "           6       0.64      0.88      0.74      1000\n",
      "           7       0.75      0.75      0.75      1000\n",
      "           8       0.77      0.81      0.79      1000\n",
      "           9       0.66      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.70     10000\n",
      "weighted avg       0.72      0.71      0.70     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [3, 5, 7, 10, 11, 13, 15, 17, 19]:\n",
    "    y_pred = brute_force_knn(distance=\"euclidean\", train_data=train_cls_tokens, train_labels=train_labels, test_data=test_cls_tokens, top_k=k)\n",
    "    print('----------------------------')\n",
    "    print(f'EUCLIDEAN - TOP_K: {k}')\n",
    "    print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Patch Embeddings\n",
    "\n",
    "In the following cells we will try to find the labels from the test images by doing the following:\n",
    "\n",
    "1) Use the `ViT` model to extract the patch_embeddings for the test image\n",
    "2) Find the `topK` similar patch embeddings for __each patch of the test image__\n",
    "3) Find a `y_pred` for __each patch of the test image__\n",
    "4) Assign the final y_pred to the majority\n",
    "5) \n",
    "__This method will act as our baseline__ as it does not require a finetuned Visual Transformer.\n",
    "\n",
    "The method bellow implements the brute force KNN, using the CLS embeddings for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:41:31.278043Z",
     "iopub.status.busy": "2025-01-28T18:41:31.277458Z",
     "iopub.status.idle": "2025-01-28T18:41:31.289100Z",
     "shell.execute_reply": "2025-01-28T18:41:31.287229Z",
     "shell.execute_reply.started": "2025-01-28T18:41:31.277992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def patch_brute_force_knn(distance: str, train_data: list, train_labels: np.array, test_data: list, top_k: int = 5):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "    \n",
    "    # Move train_data back to cpu\n",
    "    # train_data = [img.to('cpu') for img in train_data]\n",
    "    print('Will set labels to cpu')\n",
    "    clean_labels = []\n",
    "    for label in tqdm(train_labels, total=len(train_labels), desc=\"Converting labels to cpu\"):\n",
    "        clean_labels.append(label.to('cpu'))\n",
    "\n",
    "    # Create a numpy array from the list\n",
    "    print(f'Total train images: {len(train_data)}')\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    clean_labels = np.stack(clean_labels, axis=0)\n",
    "    print(f'Train shape: {train_data.shape}')\n",
    "    print(f'Train labels shape: {clean_labels.shape}')\n",
    "    \n",
    "    # Fit with the train set\n",
    "    print('Will fit train data to KNN')\n",
    "    knn.fit(train_data)\n",
    "    \n",
    "    # Create a numpy array for the test images\n",
    "    print(f'Total test images: {len(test_data)}')\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f'Test shape: {test_data.shape}')\n",
    "\n",
    "    y_pred = []\n",
    "    # For each image\n",
    "    for i in tqdm(range(test_data.shape[0]), desc='Gathering results'):\n",
    "        # Apply the knn for each patch\n",
    "        # Note that the initial test array has a shape of\n",
    "        # (num_test, num_image_patches, hidden_dim)\n",
    "        patch_distances, patch_indexes = knn.kneighbors(test_data[i, :, :], return_distance=True)\n",
    "        # print(patch_distances.shape)\n",
    "        # print(patch_indexes.shape)\n",
    "        patch_y_pred = []\n",
    "        # Now for each patch we have to get a class\n",
    "        for p in range(patch_indexes.shape[0]):\n",
    "            # Get the classes of the top_k\n",
    "            # print(patch_indexes[p])\n",
    "            # print(clean_labels[patch_indexes[p]])\n",
    "            classes = clean_labels[patch_indexes[p, :]]\n",
    "            # Select the majority and keep it in the list\n",
    "            # print(most_common(classes.tolist()))\n",
    "            patch_y_pred.append(most_common(classes.tolist()))\n",
    "\n",
    "        # print(patch_y_pred)\n",
    "        # print(len(patch_y_pred))\n",
    "        # Now from the patch_y_pred get the majority as the final class label\n",
    "        y_pred.append(most_common(patch_y_pred))\n",
    "\n",
    "    # finally convert the y_pred to array\n",
    "    y_pred = np.stack(y_pred, axis=0)\n",
    "\n",
    "    return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:41:33.243941Z",
     "iopub.status.busy": "2025-01-28T18:41:33.243526Z",
     "iopub.status.idle": "2025-01-28T19:00:05.717247Z",
     "shell.execute_reply": "2025-01-28T19:00:05.716006Z",
     "shell.execute_reply.started": "2025-01-28T18:41:33.243912Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu:   0%|          | 964/890624 [00:00<05:34, 2660.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 890624/890624 [02:22<00:00, 6247.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 890624\n",
      "Train shape: (890624, 192)\n",
      "Train labels shape: (890624,)\n",
      "Will fit train data to KNN\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 196, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [8:34:05<00:00,  3.08s/it]  \n"
     ]
    }
   ],
   "source": [
    "results = patch_brute_force_knn(\"cosine\", patch_embeddings, patch_labels, test_patch_embeddings, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T19:21:19.918011Z",
     "iopub.status.busy": "2025-01-28T19:21:19.917070Z",
     "iopub.status.idle": "2025-01-28T19:21:19.949324Z",
     "shell.execute_reply": "2025-01-28T19:21:19.947766Z",
     "shell.execute_reply.started": "2025-01-28T19:21:19.917961Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72      1010\n",
      "           1       0.80      0.79      0.79      1010\n",
      "           2       0.42      0.85      0.56       491\n",
      "           3       0.46      0.64      0.53       724\n",
      "           4       0.64      0.68      0.66       941\n",
      "           5       0.67      0.64      0.65      1041\n",
      "           6       0.84      0.66      0.74      1286\n",
      "           7       0.78      0.69      0.74      1128\n",
      "           8       0.77      0.81      0.79       949\n",
      "           9       0.88      0.62      0.73      1420\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.71      0.69     10000\n",
      "weighted avg       0.73      0.70      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_patch_labels = [ label[0].to('cpu') for label in test_patch_labels ]\n",
    "\n",
    "print(classification_report(results, test_patch_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Method\n",
    "\n",
    "Generate and return __for each patch of a test image__:\n",
    "\n",
    "1. The top_k similar patches from the memory\n",
    "2. The class of each top_k similar patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def get_neigbors_and_labels_patch(\n",
    "    distance: str,\n",
    "    train_data: list,\n",
    "    train_labels: np.array,\n",
    "    test_data: list,\n",
    "    top_k: int = 5,\n",
    "):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "\n",
    "    # Move train_data back to cpu\n",
    "    # train_data = [img.to('cpu') for img in train_data]\n",
    "    print(\"Will set labels to cpu\")\n",
    "    clean_labels = []\n",
    "    for label in tqdm(\n",
    "        train_labels, total=len(train_labels), desc=\"Converting labels to cpu\"\n",
    "    ):\n",
    "        clean_labels.append(label.to(\"cpu\"))\n",
    "\n",
    "    # Create a numpy array from the list\n",
    "    print(f\"Total train images: {len(train_data)}\")\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    clean_labels = np.stack(clean_labels, axis=0)\n",
    "    print(f\"Train shape: {train_data.shape}\")\n",
    "    print(f\"Train labels shape: {clean_labels.shape}\")\n",
    "\n",
    "    # Fit with the train set\n",
    "    print(\"Will fit train data to KNN\")\n",
    "    knn.fit(train_data)\n",
    "\n",
    "    # Create a numpy array for the test images\n",
    "    print(f\"Total test images: {len(test_data)}\")\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f\"Test shape: {test_data.shape}\")\n",
    "\n",
    "    neighbor_patches = []\n",
    "    neighbor_classes = []\n",
    "    # For each image\n",
    "    for i in tqdm(range(test_data.shape[0]), desc=\"Gathering results\"):\n",
    "        # Apply the knn for each patch\n",
    "        # Note that the initial test array has a shape of\n",
    "        # (num_test, num_image_patches, hidden_dim)\n",
    "        b_patch_distances, b_patch_indexes = knn.kneighbors(\n",
    "            test_data[i, :, :], return_distance=True\n",
    "        )\n",
    "\n",
    "        # These have a shape of (num_patches, k)\n",
    "\n",
    "        # We now want to find the k classes for each test patch neighbors\n",
    "        b_patch_classes = []\n",
    "        b_patches = []\n",
    "\n",
    "        # Now for each patch we have to get a class\n",
    "        for p in range(b_patch_indexes.shape[0]):\n",
    "            # Get the classes of the top_k\n",
    "            classes = clean_labels[b_patch_indexes[p, :]]\n",
    "            # Get the actual patches of the top_k\n",
    "            patches = train_data[b_patch_indexes[p, :]]\n",
    "\n",
    "            b_patch_classes.append(classes)\n",
    "            b_patches.append(patches)\n",
    "\n",
    "        # Now we can add all the neighbor distances and their classes to our final lists\n",
    "        neighbor_patches.append(b_patches)\n",
    "        neighbor_classes.append(b_patch_classes)\n",
    "\n",
    "    # finally convert the lists to arrays\n",
    "    # Again, each list element has a shape of (k,)\n",
    "    # In patch distances it's the distance of each neighbor\n",
    "    # In patch classes it's the class of each neighbor\n",
    "    # Both are with respect to a SINGLE test patch\n",
    "    neighbor_patches = np.stack(neighbor_patches, axis=0)\n",
    "    neighbor_classes = np.stack(neighbor_classes, axis=0)\n",
    "\n",
    "    return neighbor_patches, neighbor_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T21:34:24.069236Z",
     "iopub.status.busy": "2025-01-27T21:34:24.068817Z",
     "iopub.status.idle": "2025-01-27T21:34:24.074666Z",
     "shell.execute_reply": "2025-01-27T21:34:24.073432Z",
     "shell.execute_reply.started": "2025-01-27T21:34:24.069200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_patch_memory(\n",
    "    output_folder: str,\n",
    "    file_name: str,\n",
    "    test_patch,\n",
    "    test_patch_labels,\n",
    "    test_patch_neighbors,\n",
    "    test_patch_neighbor_labels,\n",
    "):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Define the save file path\n",
    "    save_path = os.path.join(output_folder, file_name + \".npz\")\n",
    "\n",
    "    # Save the arrays\n",
    "    np.savez(\n",
    "        save_path,\n",
    "        test_patch=test_patch,\n",
    "        test_labels=test_patch_labels,\n",
    "        neighbor_path=test_patch_neighbors,\n",
    "        neighbor_labels=test_patch_neighbor_labels,\n",
    "    )\n",
    "    print(f\"Data saved successfully to {save_path}\")\n",
    "\n",
    "def save_cls_memory(\n",
    "    output_folder: str,\n",
    "    file_name: str,\n",
    "    test_cls,\n",
    "    test_cls_labels,\n",
    "    test_cls_neighbors,\n",
    "    test_cls_neighbor_labels,\n",
    "):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Define the save file path\n",
    "    save_path = os.path.join(output_folder, file_name + \".npz\")\n",
    "\n",
    "    # Save the arrays\n",
    "    np.savez(\n",
    "        save_path,\n",
    "        test_cls=test_cls,\n",
    "        test_labels=test_cls_labels,\n",
    "        neighbor_path=test_cls_neighbors,\n",
    "        neighbor_labels=test_cls_neighbor_labels,\n",
    "    )\n",
    "    print(f\"Data saved successfully to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 890624/890624 [02:06<00:00, 7065.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 890624\n",
      "Train shape: (890624, 192)\n",
      "Train labels shape: (890624,)\n",
      "Will fit train data to KNN\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 196, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [10:04:34<00:00,  3.63s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors: (10000, 196, 5, 192)\n",
      "Classes: (10000, 196, 5)\n"
     ]
    }
   ],
   "source": [
    "neighbors, classes = get_neigbors_and_labels_patch(\n",
    "    \"cosine\", patch_embeddings, patch_labels, test_patch_embeddings, 5\n",
    ")\n",
    "\n",
    "print(f\"Neighbors: {neighbors.shape}\")\n",
    "print(f\"Classes: {classes.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting test labels to cpu: 100%|██████████| 10000/10000 [00:06<00:00, 1656.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patches: (10000, 196, 192)\n",
      "Test labels: (10000,)\n",
      "Neighbors: (10000, 196, 5, 192)\n",
      "Classes: (10000, 196, 5)\n",
      "Data saved successfully to ./patch_memory.npz\n"
     ]
    }
   ],
   "source": [
    "# Convert the test labels to cpu and change them to (test_size,)\n",
    "clean_test_labels = []\n",
    "for image in tqdm(test_patch_labels, desc='Converting test labels to cpu'):\n",
    "    # We can do this here as all the patches of a test image have the same label\n",
    "    clean_test_labels.append(image[0].to('cpu'))\n",
    "\n",
    "clean_test_labels = np.stack(clean_test_labels, axis=0)\n",
    "\n",
    "# Convert the patch embeddings to array\n",
    "test_patches = np.stack(test_patch_embeddings, axis=0)\n",
    "\n",
    "print(f'Test patches: {test_patches.shape}')\n",
    "print(f'Test labels: {clean_test_labels.shape}')\n",
    "print(f\"Neighbors: {neighbors.shape}\")\n",
    "print(f\"Classes: {classes.shape}\")\n",
    "\n",
    "save_patch_memory(output_folder='./', file_name='patch_memory', test_patch=test_patches, test_patch_labels=clean_test_labels, test_patch_neighbors=neighbors, test_patch_neighbor_labels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patches: (10000, 196, 192)\n",
      "Test labels: (10000,)\n",
      "Neighbors: (4, 196, 5, 192)\n",
      "Classes: (4, 196, 5)\n"
     ]
    }
   ],
   "source": [
    "with np.load('/home/panos/WSL_projects/rag-enhanced-image-classification/src/development/patch_memory.npz') as data:\n",
    "    tp = data['test_patch']\n",
    "    tl = data['test_labels']\n",
    "    n=data['neighbor_path']\n",
    "    c=data['neighbor_labels']\n",
    "\n",
    "print(f'Test patches: {tp.shape}')\n",
    "print(f'Test labels: {tl.shape}')\n",
    "print(f\"Neighbors: {n.shape}\")\n",
    "print(f\"Classes: {c.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T18:43:19.611814Z",
     "iopub.status.busy": "2025-01-22T18:43:19.611406Z",
     "iopub.status.idle": "2025-01-22T18:43:29.052889Z",
     "shell.execute_reply": "2025-01-22T18:43:29.051516Z",
     "shell.execute_reply.started": "2025-01-22T18:43:19.611774Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 586533.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbor Distances: (10000, 13)\n",
      "Neighbor Labels: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "neighbor_distances, neighbor_labels = get_neighbors_distances_and_labels(distance=\"cosine\", train_data=train_cls_tokens, train_labels=train_labels, test_data=test_cls_tokens, top_k=13)\n",
    "\n",
    "print(f'Neighbor Distances: {neighbor_distances.shape}')\n",
    "print(f'Neighbor Labels: {neighbor_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T18:48:51.947741Z",
     "iopub.status.busy": "2025-01-24T18:48:51.947271Z",
     "iopub.status.idle": "2025-01-24T18:48:59.935751Z",
     "shell.execute_reply": "2025-01-24T18:48:59.934650Z",
     "shell.execute_reply.started": "2025-01-24T18:48:51.947671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting test labels to cpu: 100%|██████████| 10000/10000 [00:04<00:00, 2156.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k: 3 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:10<00:00, 4321.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 3)\n",
      "Indexes: (10000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 65190.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_3.npz\n",
      "Processing k: 5 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:14<00:00, 3003.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 5)\n",
      "Indexes: (10000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 59676.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_5.npz\n",
      "Processing k: 7 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:13<00:00, 3366.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 7)\n",
      "Indexes: (10000, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 60137.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_7.npz\n",
      "Processing k: 10 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:14<00:00, 3207.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 10)\n",
      "Indexes: (10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 49145.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_10.npz\n",
      "Processing k: 11 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:17<00:00, 2572.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 11)\n",
      "Indexes: (10000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 51294.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_11.npz\n",
      "Processing k: 13 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:16<00:00, 2665.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 47012.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_13.npz\n",
      "Processing k: 15 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:13<00:00, 3344.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 15)\n",
      "Indexes: (10000, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 50674.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_15.npz\n",
      "Processing k: 17 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:13<00:00, 3447.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 17)\n",
      "Indexes: (10000, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 50438.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_17.npz\n",
      "Processing k: 19 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:12<00:00, 3553.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 19)\n",
      "Indexes: (10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 42491.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_19.npz\n",
      "Processing k: 3 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:13<00:00, 3218.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 3)\n",
      "Indexes: (10000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 64040.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_3.npz\n",
      "Processing k: 5 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:12<00:00, 3737.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 5)\n",
      "Indexes: (10000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 86711.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_5.npz\n",
      "Processing k: 7 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:17<00:00, 2574.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 7)\n",
      "Indexes: (10000, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 53133.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_7.npz\n",
      "Processing k: 10 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:35<00:00, 1285.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 10)\n",
      "Indexes: (10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 72705.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_10.npz\n",
      "Processing k: 11 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:25<00:00, 1761.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 11)\n",
      "Indexes: (10000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 64055.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_11.npz\n",
      "Processing k: 13 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:11<00:00, 3962.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 56769.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_13.npz\n",
      "Processing k: 15 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:09<00:00, 4922.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 15)\n",
      "Indexes: (10000, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 52186.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_15.npz\n",
      "Processing k: 17 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:11<00:00, 4072.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 17)\n",
      "Indexes: (10000, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 57341.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_17.npz\n",
      "Processing k: 19 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:10<00:00, 4263.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 19)\n",
      "Indexes: (10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 40512.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_19.npz\n"
     ]
    }
   ],
   "source": [
    "# We want to extract neighbors and classes for the following K\n",
    "K = [3, 5, 7, 10, 11, 13, 15, 17, 19]\n",
    "# We want each K to be tested with cosine and euclidean\n",
    "distances = [\"cosine\"] * len(K) + [\"euclidean\"] * len(K)\n",
    "# So we have to double the Ks\n",
    "K = K * 2\n",
    "\n",
    "output_folder = \"./\"\n",
    "\n",
    "# Convert the test labels to cpu\n",
    "cpu_test_labels = []\n",
    "for label in tqdm(test_labels, desc='Converting test labels to cpu'):\n",
    "    cpu_test_labels.append(label.to('cpu'))\n",
    "\n",
    "# Now also convert to numpy array\n",
    "cpu_test_labels = np.stack(cpu_test_labels, axis=0)\n",
    "\n",
    "for distance, k in zip(distances, K):\n",
    "    \n",
    "    print(f'Processing k: {k} - Distances: {distance}')\n",
    "\n",
    "    # calculate\n",
    "    neighbor_cls, neighbor_labels = get_neighbors_and_labels(\n",
    "        distance=distance,\n",
    "        train_data=train_cls_tokens,\n",
    "        train_labels=train_labels,\n",
    "        test_data=test_cls_tokens,\n",
    "        top_k=k,\n",
    "    )\n",
    "\n",
    "    file_name = f\"cls_neighbors_{distance}_{k}\"\n",
    "\n",
    "    test_cls_tokens_arr = np.stack(test_cls_tokens, axis=0)\n",
    "\n",
    "    # now save to npz file\n",
    "    save_cls_memory(\n",
    "        output_folder=output_folder,\n",
    "        file_name=file_name,\n",
    "        test_cls=test_cls_tokens_arr,\n",
    "        test_cls_labels=cpu_test_labels,\n",
    "        test_cls_neighbors=neighbor_cls,\n",
    "        test_cls_neighbor_labels=neighbor_labels,\n",
    "    )\n",
    "\n",
    "    # if distance == 'euclidean':\n",
    "        # break\n",
    "\n",
    "\n",
    "# print(f'Neighbor CLS: {neighbor_cls.shape}')\n",
    "# print(f'Neighbor Labels: {neighbor_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 196, 5)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with np.load('/home/panos/WSL_projects/rag-enhanced-image-classification/src/development/test_patch_neighbors.npz') as data:\n",
    "    item = data['data']\n",
    "\n",
    "item.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./train_loader.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(train_loader, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./test_loader.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(test_loader, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./val_loader.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(val_loader, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
