{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-24T17:44:03.832111Z",
     "iopub.status.busy": "2025-01-24T17:44:03.831760Z",
     "iopub.status.idle": "2025-01-24T17:44:16.916847Z",
     "shell.execute_reply": "2025-01-24T17:44:16.915781Z",
     "shell.execute_reply.started": "2025-01-24T17:44:03.832081Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-1.0.14-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from timm) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from timm) (0.20.1+cu124)\n",
      "Requirement already satisfied: pyyaml in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from timm) (6.0.2)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from huggingface_hub->timm) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: requests in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torchvision->timm) (2.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from torchvision->timm) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2024.12.14)\n",
      "Installing collected packages: safetensors, huggingface_hub, timm\n",
      "Successfully installed huggingface_hub-0.27.1 safetensors-0.5.2 timm-1.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yfourfouris/workspace/sign-language-image-detection/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# First make sure to install timm\n",
    "!pip install timm\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import timm\n",
    "import torchvision\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Selection\n",
    "\n",
    "We will opt for gpu, if it's available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:44:16.918484Z",
     "iopub.status.busy": "2025-01-24T17:44:16.918135Z",
     "iopub.status.idle": "2025-01-24T17:44:16.927910Z",
     "shell.execute_reply": "2025-01-24T17:44:16.926642Z",
     "shell.execute_reply.started": "2025-01-24T17:44:16.918455Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset\n",
    "\n",
    "We can use CIFAR10 or CIFAR100 as our dataset. Since both are really common datasets we will use the `torchvision.datasets` class to load them.\n",
    "\n",
    "To select the dataset, modify the `use_CIFAR10` boolean variable accordingly.\n",
    "\n",
    "We also apply some basic __preprocessing__:\n",
    "\n",
    "1. Normalize the dataset by subtracting the _mean_ and dividing with the _std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:44:16.929976Z",
     "iopub.status.busy": "2025-01-24T17:44:16.929493Z",
     "iopub.status.idle": "2025-01-24T17:44:40.268571Z",
     "shell.execute_reply": "2025-01-24T17:44:40.267464Z",
     "shell.execute_reply.started": "2025-01-24T17:44:16.929917Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset downloaded. Total images: 50000\n",
      "Train images: 45000\n",
      "Validation images: 5000\n",
      "Test images: 10000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "use_CIFAR10 = True\n",
    "\n",
    "# Get the precomputed mean and std\n",
    "# Those are needed to normalize the dataset\n",
    "# NOTE: To calculate the mean and std we have to \n",
    "# 1. calculate the sum for each channel\n",
    "# 2. implement mean and variance formulas\n",
    "if use_CIFAR10:\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std = (0.2023, 0.1994, 0.2010)\n",
    "else:\n",
    "    raise NotImplementedError(\"Please compute mean, std for CIFAR100\")\n",
    "\n",
    "# dataset directory remains the same for both cases\n",
    "dataset_directory = \"../../../cifar-10-batches-py-for-pytorch\"\n",
    "\n",
    "\n",
    "# the transformation also remains the same\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# download the dataset\n",
    "if use_CIFAR10:\n",
    "    cifar_dataset = torchvision.datasets.CIFAR10(root=dataset_directory, train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root=dataset_directory, train=False, download=True, transform=transform)\n",
    "else:\n",
    "    cifar_dataset = torchvision.datasets.CIFAR100(root=dataset_directory, train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR100(root=dataset_directory, train=False, download=True, transform=transform)\n",
    "\n",
    "print(f'Dataset downloaded. Total images: {len(cifar_dataset)}')\n",
    "\n",
    "# Split the dataset into train / valildation sets\n",
    "train_size = int(0.9 * len(cifar_dataset))\n",
    "val_size = len(cifar_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(cifar_dataset, [train_size, val_size])\n",
    "\n",
    "# set the batch size to 64\n",
    "batch_size = 64\n",
    "\n",
    "# Create some dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f'Train images: {train_size}')\n",
    "print(f'Validation images: {val_size}')\n",
    "print(f'Test images: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Methods\n",
    "\n",
    "Bellow we have created some methods to make the code simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common List Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:45:54.415183Z",
     "iopub.status.busy": "2025-01-24T17:45:54.414856Z",
     "iopub.status.idle": "2025-01-24T17:45:54.419970Z",
     "shell.execute_reply": "2025-01-24T17:45:54.418832Z",
     "shell.execute_reply.started": "2025-01-24T17:45:54.415157Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_common(lst):\n",
    "    data = Counter(lst)\n",
    "    return max(lst, key=data.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CLS Token\n",
    "\n",
    "By taking a look at the [documentation](https://huggingface.co/docs/timm/en/feature_extraction) for the timm library and specifically the __Feature Extraction__ section we can see that in order to get the __last hidden state__ of the model we have to use the `forward_features` method.\n",
    "\n",
    "Specifically, this method returns the patch embeddings at the last hidden state, __before pooling is applied__. The return vector is of shape\n",
    "\n",
    "```\n",
    "(batch_size, num_patches + 1, hidden_size)\n",
    "```\n",
    "\n",
    "The __CLS Token__ is by design the __first of the patch embeddings__\n",
    "\n",
    "For example to get the CLS Token of the first image in the batch we would have to do:\n",
    "\n",
    "```py\n",
    "model_output[0, 0, :]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:45:54.825937Z",
     "iopub.status.busy": "2025-01-24T17:45:54.825553Z",
     "iopub.status.idle": "2025-01-24T17:45:54.831061Z",
     "shell.execute_reply": "2025-01-24T17:45:54.829859Z",
     "shell.execute_reply.started": "2025-01-24T17:45:54.825906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_cls_token(model: timm.models.vision_transformer.VisionTransformer, images: torch.Tensor) -> np.array:\n",
    "    # get the last hidden state\n",
    "    output = model.forward_features(images)\n",
    "\n",
    "    # for each image get the cls token\n",
    "    # make sure to convert each tensor to numpy\n",
    "    cls_tokens = output[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    return cls_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract CLS Tokens for all images in a DataLoader\n",
    "\n",
    "This method uses the `get_cls_token` method above to extract all cls tokens from a given dataloader.\n",
    "\n",
    "For each image we will also need:\n",
    "    \n",
    "    1. it's original position (?)\n",
    "    2. the label\n",
    "\n",
    "The method returns __a dictionary__ with:\n",
    "1. __key__: The original position of the image\n",
    "2. __value__: A dictionary with `cls_token` and `label` keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:45:55.221927Z",
     "iopub.status.busy": "2025-01-24T17:45:55.221519Z",
     "iopub.status.idle": "2025-01-24T17:45:55.227970Z",
     "shell.execute_reply": "2025-01-24T17:45:55.226924Z",
     "shell.execute_reply.started": "2025-01-24T17:45:55.221892Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_dataset_cls_tokens(model: timm.models.vision_transformer.VisionTransformer, loader: torch.utils.data.dataloader.DataLoader\n",
    "):\n",
    "\n",
    "    cls_tokens = []\n",
    "    cls_labels = []\n",
    "\n",
    "    for idx, (images, labels) in tqdm(enumerate(loader), desc=\"Calculating CLS Tokens\", total=len(loader)):\n",
    "\n",
    "        # this returns a numpy array with shape\n",
    "        # (batch_size, hidden_size)\n",
    "        tokens = get_cls_token(model=model, images=images)\n",
    "\n",
    "        # For each image in the batch\n",
    "        for idx in range(tokens.shape[0]):\n",
    "            cls_tokens.append(tokens[idx, :])\n",
    "            cls_labels.append(labels[idx])\n",
    "\n",
    "    return cls_tokens, cls_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the VIT model\n",
    "\n",
    "To load the model we will use the `timm` library.\n",
    "\n",
    "We could also use the `transformers` library and more specific the `ViTForImageClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:45:57.664670Z",
     "iopub.status.busy": "2025-01-24T17:45:57.664324Z",
     "iopub.status.idle": "2025-01-24T17:45:58.984385Z",
     "shell.execute_reply": "2025-01-24T17:45:58.983377Z",
     "shell.execute_reply.started": "2025-01-24T17:45:57.664638Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    \"vit_tiny_patch16_224\",  # Pre-trained ViT-Tiny on ImageNet-1k\n",
    "    pretrained=True,        # Load pre-trained weights\n",
    "    num_classes=10          # Adapt classifier head to CIFAR-10 (10 classes)\n",
    ")\n",
    "\n",
    "# We dont want to train here so we can freeze all the layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CLS Tokens for the Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:45:59.666182Z",
     "iopub.status.busy": "2025-01-24T17:45:59.665828Z",
     "iopub.status.idle": "2025-01-24T18:09:30.103317Z",
     "shell.execute_reply": "2025-01-24T18:09:30.102260Z",
     "shell.execute_reply.started": "2025-01-24T17:45:59.666156Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating CLS Tokens: 100%|██████████| 704/704 [04:13<00:00,  2.78it/s]\n"
     ]
    }
   ],
   "source": [
    "train_cls_tokens, train_labels = get_dataset_cls_tokens(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T18:09:30.105119Z",
     "iopub.status.busy": "2025-01-24T18:09:30.104807Z",
     "iopub.status.idle": "2025-01-24T18:09:30.594176Z",
     "shell.execute_reply": "2025-01-24T18:09:30.593113Z",
     "shell.execute_reply.started": "2025-01-24T18:09:30.105093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert the labels to numpy better handling\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CLS Tokens for the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T18:09:30.597602Z",
     "iopub.status.busy": "2025-01-24T18:09:30.597309Z",
     "iopub.status.idle": "2025-01-24T18:14:43.339234Z",
     "shell.execute_reply": "2025-01-24T18:14:43.338274Z",
     "shell.execute_reply.started": "2025-01-24T18:09:30.597579Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating CLS Tokens: 100%|██████████| 157/157 [00:54<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "test_cls_tokens, test_labels = get_dataset_cls_tokens(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T18:14:43.340742Z",
     "iopub.status.busy": "2025-01-24T18:14:43.340456Z",
     "iopub.status.idle": "2025-01-24T18:14:43.408666Z",
     "shell.execute_reply": "2025-01-24T18:14:43.407836Z",
     "shell.execute_reply.started": "2025-01-24T18:14:43.340719Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# convert the labels to numpy better handling\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute Force KNN - WITHOUT Test Prediction\n",
    "\n",
    "In the following cells we will try to find the labels from the test images by doing the following:\n",
    "\n",
    "1) Use the `ViT` model to extract the cls_token for the test image\n",
    "2) Find the `topK` similar cls_tokens from the train dataset\n",
    "3) Assign the `y_pred` to the majority class from the KNN\n",
    "\n",
    "__This method will act as our baseline__ as it does not require a finetuned Visual Transformer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T18:14:43.411810Z",
     "iopub.status.busy": "2025-01-24T18:14:43.411498Z",
     "iopub.status.idle": "2025-01-24T18:14:43.419205Z",
     "shell.execute_reply": "2025-01-24T18:14:43.418036Z",
     "shell.execute_reply.started": "2025-01-24T18:14:43.411783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def brute_force_knn(distance: str, train_data: np.array, train_labels: np.array, test_data: np.array, top_k: int = 5):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "    \n",
    "    # Create a numpy array from the list\n",
    "    print(f'Total train images: {len(train_data)}')\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    print(f'Train shape: {train_data.shape}')\n",
    "    \n",
    "    # Fit with the train set\n",
    "    knn.fit(train_data)\n",
    "    \n",
    "    # Create a numpy array for the test images\n",
    "    print(f'Total test images: {len(test_data)}')\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f'Test shape: {test_data.shape}')\n",
    "    \n",
    "    # Apply the knn\n",
    "    distances, indexes = knn.kneighbors(test_data, return_distance=True)\n",
    "    \n",
    "    print(f'Distances: {distances.shape}')\n",
    "    print(f'Indexes: {distances.shape}')\n",
    "    \n",
    "    y_pred = []\n",
    "    # Gather the final y_pred\n",
    "    # For each test image\n",
    "    for i in tqdm(range(indexes.shape[0]), desc='Gathering results'):\n",
    "        # Get the classes of the top_k\n",
    "        classes = train_labels[indexes[i]]\n",
    "        # Select the majority as y_pred\n",
    "        y_pred.append(most_common(classes.tolist()))\n",
    "    \n",
    "    # finally convert the y_pred to array\n",
    "    y_pred = np.stack(y_pred, axis=0)\n",
    "\n",
    "    return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Method: Get Neighbors and Labels\n",
    "\n",
    "This method will be used by other parts of the project. It returns two items:\n",
    "\n",
    "1. `cls_tokens`: An array of shape (num_test, k): Each row contains the cls_token that corresponds the the neighbor.\n",
    "2. `labels`: An array of shape (num_test, k): Each row contains the labels of those top-k images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T18:48:28.535868Z",
     "iopub.status.busy": "2025-01-24T18:48:28.535369Z",
     "iopub.status.idle": "2025-01-24T18:48:28.543882Z",
     "shell.execute_reply": "2025-01-24T18:48:28.542666Z",
     "shell.execute_reply.started": "2025-01-24T18:48:28.535828Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def get_neighbors_and_labels(distance: str, train_data: np.array, train_labels: list, test_data: list, test_labels: list, top_k: int = 5):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "    \n",
    "    # Create a numpy array from the list\n",
    "    print(f'Total train images: {len(train_data)}')\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    test_labels = np.stack(test_labels, axis=0)\n",
    "    print(f'Train shape: {train_data.shape}')\n",
    "    \n",
    "    # Fit with the train set\n",
    "    knn.fit(train_data)\n",
    "    \n",
    "    # Create a numpy array for the test images\n",
    "    print(f'Total test images: {len(test_data)}')\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f'Test shape: {test_data.shape}')\n",
    "    \n",
    "    # Apply the knn\n",
    "    distances, indexes = knn.kneighbors(test_data, return_distance=True)\n",
    "    \n",
    "    print(f'Distances: {distances.shape}')\n",
    "    print(f'Indexes: {distances.shape}')\n",
    "    \n",
    "    neighbor_labels = []\n",
    "    neighbor_cls_tokens = []\n",
    "    # Gather the final labels\n",
    "    # And the cls_tokens\n",
    "    # For each test image\n",
    "    for i in tqdm(range(indexes.shape[0]), desc='Gathering results'):\n",
    "        # Get the classes of the top_k\n",
    "        classes = train_labels[indexes[i]]\n",
    "        neighbor_labels.append(classes)\n",
    "        \n",
    "        # Get the cls_tokens of the top_k\n",
    "        cls_tokens = train_data[indexes[i]]\n",
    "        neighbor_cls_tokens.append(cls_tokens)\n",
    "    \n",
    "    # finally convert the the labels to array\n",
    "    neighbor_labels = np.stack(neighbor_labels, axis=0)\n",
    "    # Do the same for the cls\n",
    "    neighbor_cls_tokens = np.stack(neighbor_cls_tokens, axis=0)\n",
    "    \n",
    "    return test_data, test_labels, neighbor_cls_tokens, neighbor_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Method: Get Neighbor Distances and Labels\n",
    "\n",
    "This method will be used by other parts of the project. It returns two items:\n",
    "\n",
    "1. `distances`: An array of shape (num_test, k): Each row contains the distances of the top-k similar images from the train set.\n",
    "2. `labels`: An array of shape (num_test, k): Each row contains the labels of those top-k images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:45:29.273744Z",
     "iopub.status.busy": "2025-01-24T17:45:29.273358Z",
     "iopub.status.idle": "2025-01-24T17:45:29.280994Z",
     "shell.execute_reply": "2025-01-24T17:45:29.279872Z",
     "shell.execute_reply.started": "2025-01-24T17:45:29.273712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def get_neighbors_distances_and_labels(distance: str, train_data: list, train_labels: np.array, test_data: np.array, top_k: int = 5):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "    \n",
    "    # Create a numpy array from the list\n",
    "    print(f'Total train images: {len(train_data)}')\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    print(f'Train shape: {train_data.shape}')\n",
    "    \n",
    "    # Fit with the train set\n",
    "    knn.fit(train_data)\n",
    "    \n",
    "    # Create a numpy array for the test images\n",
    "    print(f'Total test images: {len(test_data)}')\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f'Test shape: {test_data.shape}')\n",
    "    \n",
    "    # Apply the knn\n",
    "    distances, indexes = knn.kneighbors(test_data, return_distance=True)\n",
    "    \n",
    "    print(f'Distances: {distances.shape}')\n",
    "    print(f'Indexes: {distances.shape}')\n",
    "    \n",
    "    neighbor_labels = []\n",
    "    # Gather the final labels\n",
    "    # For each test image\n",
    "    for i in tqdm(range(indexes.shape[0]), desc='Gathering results'):\n",
    "        # Get the classes of the top_k\n",
    "        classes = train_labels[indexes[i]]\n",
    "        neighbor_labels.append(classes)\n",
    "    \n",
    "    # finally convert the the labels to array\n",
    "    neighbor_labels = np.stack(neighbor_labels, axis=0)\n",
    "\n",
    "    return distances, neighbor_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T22:50:43.849080Z",
     "iopub.status.busy": "2025-01-21T22:50:43.848583Z",
     "iopub.status.idle": "2025-01-21T22:51:52.473499Z",
     "shell.execute_reply": "2025-01-21T22:51:52.472238Z",
     "shell.execute_reply.started": "2025-01-21T22:50:43.849048Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 3)\n",
      "Indexes: (10000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 291172.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      1000\n",
      "           1       0.70      0.72      0.71      1000\n",
      "           2       0.78      0.55      0.65      1000\n",
      "           3       0.56      0.49      0.52      1000\n",
      "           4       0.69      0.65      0.67      1000\n",
      "           5       0.61      0.60      0.61      1000\n",
      "           6       0.67      0.84      0.74      1000\n",
      "           7       0.70      0.77      0.73      1000\n",
      "           8       0.80      0.77      0.78      1000\n",
      "           9       0.66      0.76      0.71      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.69      0.69     10000\n",
      "weighted avg       0.69      0.69      0.69     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 5)\n",
      "Indexes: (10000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 277417.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.72      0.75      0.74      1000\n",
      "           2       0.84      0.55      0.66      1000\n",
      "           3       0.59      0.53      0.56      1000\n",
      "           4       0.71      0.67      0.69      1000\n",
      "           5       0.63      0.63      0.63      1000\n",
      "           6       0.66      0.86      0.75      1000\n",
      "           7       0.73      0.78      0.75      1000\n",
      "           8       0.80      0.79      0.79      1000\n",
      "           9       0.66      0.79      0.72      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.71     10000\n",
      "weighted avg       0.71      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 7)\n",
      "Indexes: (10000, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 260966.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1000\n",
      "           1       0.74      0.75      0.75      1000\n",
      "           2       0.85      0.53      0.65      1000\n",
      "           3       0.59      0.53      0.56      1000\n",
      "           4       0.73      0.68      0.70      1000\n",
      "           5       0.64      0.63      0.64      1000\n",
      "           6       0.66      0.88      0.75      1000\n",
      "           7       0.73      0.79      0.76      1000\n",
      "           8       0.82      0.79      0.81      1000\n",
      "           9       0.66      0.81      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 10)\n",
      "Indexes: (10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 235759.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1000\n",
      "           1       0.75      0.76      0.75      1000\n",
      "           2       0.86      0.51      0.64      1000\n",
      "           3       0.60      0.53      0.56      1000\n",
      "           4       0.73      0.68      0.70      1000\n",
      "           5       0.64      0.64      0.64      1000\n",
      "           6       0.64      0.88      0.74      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.82      0.78      0.80      1000\n",
      "           9       0.66      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 11)\n",
      "Indexes: (10000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 236574.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1000\n",
      "           1       0.75      0.76      0.75      1000\n",
      "           2       0.87      0.51      0.64      1000\n",
      "           3       0.60      0.53      0.56      1000\n",
      "           4       0.74      0.68      0.71      1000\n",
      "           5       0.64      0.65      0.64      1000\n",
      "           6       0.64      0.88      0.74      1000\n",
      "           7       0.73      0.78      0.76      1000\n",
      "           8       0.81      0.79      0.80      1000\n",
      "           9       0.66      0.81      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 222072.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1000\n",
      "           1       0.76      0.77      0.76      1000\n",
      "           2       0.88      0.51      0.64      1000\n",
      "           3       0.61      0.54      0.57      1000\n",
      "           4       0.74      0.68      0.71      1000\n",
      "           5       0.64      0.65      0.64      1000\n",
      "           6       0.64      0.89      0.75      1000\n",
      "           7       0.75      0.79      0.77      1000\n",
      "           8       0.83      0.80      0.81      1000\n",
      "           9       0.66      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.72     10000\n",
      "weighted avg       0.73      0.72      0.72     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 15)\n",
      "Indexes: (10000, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 210068.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1000\n",
      "           1       0.75      0.76      0.75      1000\n",
      "           2       0.88      0.50      0.64      1000\n",
      "           3       0.60      0.54      0.56      1000\n",
      "           4       0.73      0.68      0.70      1000\n",
      "           5       0.64      0.64      0.64      1000\n",
      "           6       0.64      0.89      0.75      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.83      0.79      0.81      1000\n",
      "           9       0.66      0.83      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.71      0.71     10000\n",
      "weighted avg       0.73      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 17)\n",
      "Indexes: (10000, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 195759.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1000\n",
      "           1       0.75      0.76      0.76      1000\n",
      "           2       0.90      0.49      0.64      1000\n",
      "           3       0.60      0.54      0.56      1000\n",
      "           4       0.74      0.67      0.70      1000\n",
      "           5       0.64      0.65      0.64      1000\n",
      "           6       0.64      0.89      0.74      1000\n",
      "           7       0.74      0.77      0.75      1000\n",
      "           8       0.82      0.79      0.80      1000\n",
      "           9       0.65      0.83      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.71      0.71     10000\n",
      "weighted avg       0.73      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 19)\n",
      "Indexes: (10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 201624.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.75      0.76      0.75      1000\n",
      "           2       0.91      0.49      0.64      1000\n",
      "           3       0.61      0.54      0.57      1000\n",
      "           4       0.74      0.67      0.70      1000\n",
      "           5       0.65      0.66      0.65      1000\n",
      "           6       0.64      0.89      0.74      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.82      0.79      0.81      1000\n",
      "           9       0.65      0.83      0.73      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.71     10000\n",
      "weighted avg       0.73      0.72      0.71     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [3, 5, 7, 10, 11, 13, 15, 17, 19]:\n",
    "    y_pred = brute_force_knn(distance=\"cosine\", train_data=train_cls_tokens, train_labels=train_labels, test_data=test_cls_tokens, top_k=k)\n",
    "    print('----------------------------')\n",
    "    print(f'COSINE - TOP_K: {k}')\n",
    "    print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Euclidian Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T22:53:26.531313Z",
     "iopub.status.busy": "2025-01-21T22:53:26.530905Z",
     "iopub.status.idle": "2025-01-21T22:54:02.469690Z",
     "shell.execute_reply": "2025-01-21T22:54:02.468656Z",
     "shell.execute_reply.started": "2025-01-21T22:53:26.531280Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 3)\n",
      "Indexes: (10000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 296849.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72      1000\n",
      "           1       0.71      0.70      0.71      1000\n",
      "           2       0.75      0.53      0.62      1000\n",
      "           3       0.53      0.49      0.51      1000\n",
      "           4       0.67      0.66      0.66      1000\n",
      "           5       0.60      0.59      0.59      1000\n",
      "           6       0.68      0.82      0.74      1000\n",
      "           7       0.71      0.77      0.74      1000\n",
      "           8       0.75      0.77      0.76      1000\n",
      "           9       0.66      0.74      0.70      1000\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.68      0.68      0.67     10000\n",
      "weighted avg       0.68      0.68      0.67     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 5)\n",
      "Indexes: (10000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 276519.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74      1000\n",
      "           1       0.73      0.72      0.73      1000\n",
      "           2       0.79      0.52      0.63      1000\n",
      "           3       0.56      0.50      0.53      1000\n",
      "           4       0.67      0.68      0.67      1000\n",
      "           5       0.62      0.61      0.61      1000\n",
      "           6       0.68      0.85      0.76      1000\n",
      "           7       0.73      0.75      0.74      1000\n",
      "           8       0.76      0.78      0.77      1000\n",
      "           9       0.66      0.77      0.71      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.69      0.69     10000\n",
      "weighted avg       0.69      0.69      0.69     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 7)\n",
      "Indexes: (10000, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 255840.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75      1000\n",
      "           1       0.75      0.73      0.74      1000\n",
      "           2       0.82      0.51      0.63      1000\n",
      "           3       0.57      0.52      0.54      1000\n",
      "           4       0.69      0.68      0.69      1000\n",
      "           5       0.63      0.62      0.62      1000\n",
      "           6       0.66      0.86      0.75      1000\n",
      "           7       0.73      0.76      0.75      1000\n",
      "           8       0.77      0.80      0.78      1000\n",
      "           9       0.66      0.80      0.73      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.70     10000\n",
      "weighted avg       0.71      0.70      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 10)\n",
      "Indexes: (10000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 233521.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      1000\n",
      "           1       0.76      0.74      0.75      1000\n",
      "           2       0.84      0.51      0.63      1000\n",
      "           3       0.59      0.53      0.56      1000\n",
      "           4       0.68      0.69      0.69      1000\n",
      "           5       0.64      0.63      0.64      1000\n",
      "           6       0.67      0.87      0.76      1000\n",
      "           7       0.74      0.77      0.76      1000\n",
      "           8       0.78      0.79      0.79      1000\n",
      "           9       0.67      0.81      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 11)\n",
      "Indexes: (10000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 213484.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76      1000\n",
      "           1       0.76      0.74      0.75      1000\n",
      "           2       0.84      0.51      0.63      1000\n",
      "           3       0.58      0.52      0.55      1000\n",
      "           4       0.69      0.69      0.69      1000\n",
      "           5       0.63      0.62      0.63      1000\n",
      "           6       0.66      0.87      0.75      1000\n",
      "           7       0.74      0.77      0.75      1000\n",
      "           8       0.78      0.80      0.79      1000\n",
      "           9       0.67      0.82      0.74      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 209054.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76      1000\n",
      "           1       0.76      0.74      0.75      1000\n",
      "           2       0.85      0.49      0.62      1000\n",
      "           3       0.58      0.52      0.55      1000\n",
      "           4       0.70      0.69      0.70      1000\n",
      "           5       0.64      0.63      0.64      1000\n",
      "           6       0.65      0.88      0.75      1000\n",
      "           7       0.74      0.76      0.75      1000\n",
      "           8       0.77      0.79      0.78      1000\n",
      "           9       0.66      0.81      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 15)\n",
      "Indexes: (10000, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 207114.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.76      0.74      0.75      1000\n",
      "           2       0.86      0.48      0.62      1000\n",
      "           3       0.58      0.51      0.55      1000\n",
      "           4       0.70      0.70      0.70      1000\n",
      "           5       0.63      0.64      0.63      1000\n",
      "           6       0.65      0.88      0.75      1000\n",
      "           7       0.75      0.76      0.75      1000\n",
      "           8       0.77      0.81      0.79      1000\n",
      "           9       0.67      0.82      0.74      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.70     10000\n",
      "weighted avg       0.72      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 17)\n",
      "Indexes: (10000, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 193190.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75      1000\n",
      "           1       0.75      0.73      0.74      1000\n",
      "           2       0.87      0.48      0.61      1000\n",
      "           3       0.59      0.51      0.55      1000\n",
      "           4       0.69      0.68      0.69      1000\n",
      "           5       0.62      0.65      0.64      1000\n",
      "           6       0.65      0.88      0.75      1000\n",
      "           7       0.74      0.75      0.75      1000\n",
      "           8       0.77      0.81      0.79      1000\n",
      "           9       0.66      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.70     10000\n",
      "weighted avg       0.71      0.70      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 19)\n",
      "Indexes: (10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 191541.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.76      0.72      0.74      1000\n",
      "           2       0.87      0.48      0.62      1000\n",
      "           3       0.61      0.52      0.56      1000\n",
      "           4       0.70      0.68      0.69      1000\n",
      "           5       0.63      0.65      0.64      1000\n",
      "           6       0.64      0.88      0.74      1000\n",
      "           7       0.75      0.75      0.75      1000\n",
      "           8       0.77      0.81      0.79      1000\n",
      "           9       0.66      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.70     10000\n",
      "weighted avg       0.72      0.71      0.70     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for k in [3, 5, 7, 10, 11, 13, 15, 17, 19]:\n",
    "    y_pred = brute_force_knn(distance=\"euclidean\", train_data=train_cls_tokens, train_labels=train_labels, test_data=test_cls_tokens, top_k=k)\n",
    "    print('----------------------------')\n",
    "    print(f'COSINE - TOP_K: {k}')\n",
    "    print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T18:43:19.611814Z",
     "iopub.status.busy": "2025-01-22T18:43:19.611406Z",
     "iopub.status.idle": "2025-01-22T18:43:29.052889Z",
     "shell.execute_reply": "2025-01-22T18:43:29.051516Z",
     "shell.execute_reply.started": "2025-01-22T18:43:19.611774Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 586533.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbor Distances: (10000, 13)\n",
      "Neighbor Labels: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "neighbor_distances, neighbor_labels = get_neighbor_distances_and_labels(distance=\"cosine\", train_data=train_cls_tokens, train_labels=train_labels, test_data=test_cls_tokens, top_k=13)\n",
    "\n",
    "print(f'Neighbor Distances: {neighbor_distances.shape}')\n",
    "print(f'Neighbor Labels: {neighbor_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(output_folder: str, file_name:str, test_cls, test_labels, neighbor_cls, neighbor_labels):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Define the save file path\n",
    "    save_path = os.path.join(output_folder, file_name+\".npz\")\n",
    "\n",
    "    # Save the arrays\n",
    "    np.savez(save_path, test_cls=test_cls, test_labels = test_labels, neighbor_cls=neighbor_cls, neighbor_labels=neighbor_labels)\n",
    "    print(f\"Data saved successfully to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T18:48:51.947741Z",
     "iopub.status.busy": "2025-01-24T18:48:51.947271Z",
     "iopub.status.idle": "2025-01-24T18:48:59.935751Z",
     "shell.execute_reply": "2025-01-24T18:48:59.934650Z",
     "shell.execute_reply.started": "2025-01-24T18:48:51.947671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k=5\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 5)\n",
      "Indexes: (10000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 218656.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to output_data/memory_for_k_5.npz\n",
      "Processing k=7\n",
      "Total train images: 45000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 7)\n",
      "Indexes: (10000, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 209636.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to output_data/memory_for_k_7.npz\n",
      "Processing k=9\n",
      "Total train images: 45000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 9)\n",
      "Indexes: (10000, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 190079.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to output_data/memory_for_k_9.npz\n",
      "Processing k=11\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 11)\n",
      "Indexes: (10000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 156987.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to output_data/memory_for_k_11.npz\n",
      "Processing k=13\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 157863.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to output_data/memory_for_k_13.npz\n",
      "Processing k=15\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 15)\n",
      "Indexes: (10000, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 144008.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to output_data/memory_for_k_15.npz\n",
      "Processing k=17\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 17)\n",
      "Indexes: (10000, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 137356.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to output_data/memory_for_k_17.npz\n",
      "Processing k=19\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 19)\n",
      "Indexes: (10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 118984.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to output_data/memory_for_k_19.npz\n",
      "Processing k=21\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 21)\n",
      "Indexes: (10000, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 107730.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to output_data/memory_for_k_21.npz\n"
     ]
    }
   ],
   "source": [
    "k_list = [5,7,9,11,13,15,17,19,21]\n",
    "for k in k_list:\n",
    "    print(f'Processing k={k}')\n",
    "    test_cls, test_labels, neighbor_cls, neighbor_labels = get_neighbors_and_labels(distance=\"cosine\", train_data=train_cls_tokens, train_labels=train_labels, test_data=test_cls_tokens, test_labels = test_labels, top_k=k)\n",
    "\n",
    "    # print('#######')\n",
    "    # print(f'Test CLS: {test_cls.shape}')\n",
    "    # print(f'Test labels: {test_labels.shape}')\n",
    "    # print(f'Neighbor CLS: {neighbor_cls.shape}')\n",
    "    # print(f'Neighbor Labels: {neighbor_labels.shape}')\n",
    "\n",
    "    output_folder = \"output_data\"\n",
    "    file_name = f'memory_for_k_{k}'\n",
    "    save_data(output_folder, file_name, test_cls, test_labels, neighbor_cls, neighbor_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to output_data/neighbors_data.npz\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"output_data\"\n",
    "save_data(output_folder, test_cls, test_labels, neighbor_cls, neighbor_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
