{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-28T17:18:41.500632Z",
     "iopub.status.busy": "2025-01-28T17:18:41.500241Z",
     "iopub.status.idle": "2025-01-28T17:18:57.858939Z",
     "shell.execute_reply": "2025-01-28T17:18:57.857700Z",
     "shell.execute_reply.started": "2025-01-28T17:18:41.500599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# First make sure to install timm\n",
    "# !pip install timm\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import timm\n",
    "import torchvision\n",
    "from sklearn.metrics import classification_report\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Selection\n",
    "\n",
    "We will opt for gpu, if it's available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset\n",
    "\n",
    "We can use CIFAR10 or CIFAR100 as our dataset. Since both are really common datasets we will use the `torchvision.datasets` class to load them.\n",
    "\n",
    "To select the dataset, modify the `use_CIFAR10` boolean variable accordingly.\n",
    "\n",
    "We also apply some basic __preprocessing__:\n",
    "\n",
    "1. Normalize the dataset by subtracting the _mean_ and dividing with the _std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_mean_std(dataset):\n",
    "    \"\"\"Compute mean and standard deviation of a dataset dynamically.\"\"\"\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    \n",
    "    for images, _ in loader:\n",
    "        mean += images.mean(dim=[0, 2, 3])\n",
    "        std += images.std(dim=[0, 2, 3])\n",
    "    \n",
    "    mean /= len(loader)\n",
    "    std /= len(loader)\n",
    "    \n",
    "    return mean, std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = \"../../../cifar-10-batches-py-for-pytorch\"\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((224, 224))\n",
    "])\n",
    "\n",
    "cifar10_dataset = torchvision.datasets.CIFAR10(root=dataset_directory, train=True, download=True, transform=transform)\n",
    "mean_cifar100, std_cifar100 = compute_mean_std(cifar10_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.4915, 0.4822, 0.4466])\n",
      "Std: tensor([0.2405, 0.2371, 0.2555])\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean: {mean_cifar100}')\n",
    "print(f'Std: {std_cifar100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:19:48.873522Z",
     "iopub.status.busy": "2025-01-28T17:19:48.873015Z",
     "iopub.status.idle": "2025-01-28T17:19:56.850337Z",
     "shell.execute_reply": "2025-01-28T17:19:56.849200Z",
     "shell.execute_reply.started": "2025-01-28T17:19:48.873469Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded. Total images: 50000\n",
      "First 5 indices of train dataset: [37542, 44491, 216, 43688, 41558]\n",
      "First 5 indices of validation dataset: [17408, 40845, 3378, 22188, 44921]\n",
      "First 5 indices of test dataset: [3, 8, 8, 0, 6]\n",
      "Train images: 45000\n",
      "Validation images: 5000\n",
      "Test images: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "use_CIFAR10 = True\n",
    "\n",
    "# Get the precomputed mean and std\n",
    "if use_CIFAR10:\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std = (0.2023, 0.1994, 0.2010)\n",
    "else:\n",
    "    mean = (0.5070, 0.4865, 0.4408)\n",
    "    std = (0.2613, 0.2503, 0.2703)\n",
    "\n",
    "# Dataset directory\n",
    "dataset_directory = \"src/development/output_data\"\n",
    "\n",
    "# Transformations\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# Download the dataset\n",
    "if use_CIFAR10:\n",
    "    cifar_dataset = torchvision.datasets.CIFAR10(root=dataset_directory, train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root=dataset_directory, train=False, download=True, transform=transform)\n",
    "else:\n",
    "    cifar_dataset = torchvision.datasets.CIFAR100(root=dataset_directory, train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR100(root=dataset_directory, train=False, download=True, transform=transform)\n",
    "\n",
    "print(f'Dataset downloaded. Total images: {len(cifar_dataset)}')\n",
    "\n",
    "# Split the dataset into train / validation sets\n",
    "train_size = int(0.9 * len(cifar_dataset))\n",
    "val_size = len(cifar_dataset) - train_size\n",
    "\n",
    "# Use a fixed seed for reproducibility of random split\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = random_split(cifar_dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "# Set the batch size to 64\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoaders with shuffle enabled for train and val, and fixed seed for test\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=generator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, generator=generator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, generator=generator)\n",
    "\n",
    "# Sanity check: print first few indices of train, val, and test datasets to ensure reproducibility\n",
    "print(f\"First 5 indices of train dataset: {train_dataset.indices[:5]}\")\n",
    "print(f\"First 5 indices of validation dataset: {val_dataset.indices[:5]}\")\n",
    "print(f\"First 5 indices of test dataset: {list(test_dataset.targets[:5])}\")\n",
    "\n",
    "# Print the sizes\n",
    "print(f'Train images: {train_size}')\n",
    "print(f'Validation images: {val_size}')\n",
    "print(f'Test images: {len(test_dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have .pkl files use those\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "if os.path.isfile('./train_loader.pkl'):\n",
    "\n",
    "    print('Will load existing loaders')\n",
    "\n",
    "    with open('./train_loader.pkl', 'rb') as fp:\n",
    "        train_loader = pickle.load(fp)\n",
    "\n",
    "    with open('./test_loader.pkl', 'rb') as fp:\n",
    "        test_loader = pickle.load(fp)\n",
    "\n",
    "    with open('./val_loader.pkl', 'rb') as fp:\n",
    "        val_loader = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Methods\n",
    "\n",
    "Bellow we have created some methods to make the code simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common List Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:59:25.208551Z",
     "iopub.status.busy": "2025-01-28T17:59:25.208156Z",
     "iopub.status.idle": "2025-01-28T17:59:25.214077Z",
     "shell.execute_reply": "2025-01-28T17:59:25.212753Z",
     "shell.execute_reply.started": "2025-01-28T17:59:25.208506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def most_common(lst):\n",
    "    data = Counter(lst)\n",
    "    return max(lst, key=data.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CLS Token\n",
    "\n",
    "By taking a look at the [documentation](https://huggingface.co/docs/timm/en/feature_extraction) for the timm library and specifically the __Feature Extraction__ section we can see that in order to get the __last hidden state__ of the model we have to use the `forward_features` method.\n",
    "\n",
    "Specifically, this method returns the patch embeddings at the last hidden state, __before pooling is applied__. The return vector is of shape\n",
    "\n",
    "```\n",
    "(batch_size, num_patches + 1, hidden_size)\n",
    "```\n",
    "\n",
    "The __CLS Token__ is by design the __first of the patch embeddings__\n",
    "\n",
    "For example to get the CLS Token of the first image in the batch we would have to do:\n",
    "\n",
    "```py\n",
    "model_output[0, 0, :]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_cls_token(model: timm.models.vision_transformer.VisionTransformer, images: torch.Tensor) -> np.array:\n",
    "    # get the last hidden state\n",
    "    output = model.forward_features(images)\n",
    "\n",
    "    # for each image get the cls token\n",
    "    # make sure to convert each tensor to numpy\n",
    "    cls_tokens = output[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    return cls_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Patch Embeddings\n",
    "\n",
    "By taking a look at the [documentation](https://huggingface.co/docs/timm/en/feature_extraction) for the timm library and specifically the __Feature Extraction__ section we can see that in order to get the __last hidden state__ of the model we have to use the `forward_features` method.\n",
    "\n",
    "Specifically, this method returns the patch embeddings at the last hidden state, __before pooling is applied__. The return vector is of shape\n",
    "\n",
    "```\n",
    "(batch_size, num_patches + 1, hidden_size)\n",
    "```\n",
    "\n",
    "We want to get all the patch embeddings with an option to also include the cls.\n",
    "\n",
    "As such, to get everything except the cls we will have to do\n",
    "```py\n",
    "cls_tokens = output[:, 1:, :].cpu().numpy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:02:39.259845Z",
     "iopub.status.busy": "2025-01-28T18:02:39.259413Z",
     "iopub.status.idle": "2025-01-28T18:02:39.266165Z",
     "shell.execute_reply": "2025-01-28T18:02:39.264846Z",
     "shell.execute_reply.started": "2025-01-28T18:02:39.259808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_patch_embeddings(model: timm.models.vision_transformer.VisionTransformer, images: torch.Tensor, include_cls: bool = False) -> np.array:\n",
    "    # get the last hidden state\n",
    "    output = model.forward_features(images)\n",
    "\n",
    "    # If we dont want the cls we have to skip the first line\n",
    "    if not include_cls:\n",
    "        return output[:, 1:, :].cpu().numpy()\n",
    "    # else return the whole hidden state\n",
    "    else:\n",
    "        return output[:, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract CLS Tokens for all images in a DataLoader\n",
    "\n",
    "This method uses the `get_cls_token` method above to extract all cls tokens from a given dataloader.\n",
    "\n",
    "For each image we will also need:\n",
    "    \n",
    "    1. it's original position (?)\n",
    "    2. the label\n",
    "\n",
    "The method returns __a dictionary__ with:\n",
    "1. __key__: The original position of the image\n",
    "2. __value__: A dictionary with `cls_token` and `label` keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:20:50.334487Z",
     "iopub.status.busy": "2025-01-28T17:20:50.334115Z",
     "iopub.status.idle": "2025-01-28T17:20:50.341449Z",
     "shell.execute_reply": "2025-01-28T17:20:50.339732Z",
     "shell.execute_reply.started": "2025-01-28T17:20:50.334461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_dataset_cls_tokens(model: timm.models.vision_transformer.VisionTransformer, loader: torch.utils.data.dataloader.DataLoader\n",
    "):\n",
    "\n",
    "    cls_tokens = []\n",
    "    cls_labels = []\n",
    "\n",
    "    for idx, (images, labels) in tqdm(enumerate(loader), desc=\"Calculating CLS Tokens\", total=len(loader)):\n",
    "        # move to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # this returns a numpy array with shape\n",
    "        # (batch_size, hidden_size)\n",
    "        tokens = get_cls_token(model=model, images=images)\n",
    "\n",
    "        # For each image in the batch\n",
    "        for idx in range(tokens.shape[0]):\n",
    "            cls_tokens.append(tokens[idx, :])\n",
    "            cls_labels.append(labels[idx])\n",
    "\n",
    "    return cls_tokens, cls_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Patch Embeddings for all images in DataLoader\n",
    "\n",
    "This method uses the `get_patch_embeddings` method above to extract all patch embeddings from a given dataloder.\n",
    "\n",
    "__NOTES__:\n",
    "- Each image has multiple patch embeddings.\n",
    "- Each patch embedding will have the shame label as it's source image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:19:19.446837Z",
     "iopub.status.busy": "2025-01-28T18:19:19.446360Z",
     "iopub.status.idle": "2025-01-28T18:19:19.456692Z",
     "shell.execute_reply": "2025-01-28T18:19:19.455208Z",
     "shell.execute_reply.started": "2025-01-28T18:19:19.446807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_dataset_patch_embeddings(model: timm.models.vision_transformer.VisionTransformer, loader: torch.utils.data.dataloader.DataLoader, include_cls: bool = False, is_test: bool = False\n",
    "):\n",
    "\n",
    "    patch_embeddings = []\n",
    "    patch_labels = []\n",
    "\n",
    "    for cnt, (images, labels) in tqdm(enumerate(loader), desc=\"Calculating Patch Embeddings\", total=len(loader)):\n",
    "\n",
    "        # move to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # this returns a numpy array with shape\n",
    "        # (batch_size, num_patches, hidden_size)\n",
    "        embs = get_patch_embeddings(model=model, images=images, include_cls=include_cls)\n",
    "\n",
    "        # For each image in the batch\n",
    "        for idx in range(embs.shape[0]):\n",
    "            # If we are not calculating for the test, we simply need a label for each patch\n",
    "            if not is_test:\n",
    "                # For each patch\n",
    "                for p_idx in range(embs.shape[1]):\n",
    "                    patch_embeddings.append(embs[idx, p_idx, :])\n",
    "                    patch_labels.append(labels[idx])\n",
    "            # Else we want to keep track of patches that belong in a single image\n",
    "            else:\n",
    "                image_embs = []\n",
    "                image_labels = []\n",
    "                for p_idx in range(embs.shape[1]):\n",
    "                    image_embs.append(embs[idx, p_idx, :])\n",
    "                    image_labels.append(labels[idx])\n",
    "\n",
    "                # Now add to the original lists\n",
    "                patch_embeddings.append(image_embs)\n",
    "                patch_labels.append(image_labels)\n",
    "\n",
    "        if not is_test and cnt == 70:\n",
    "            break\n",
    "    \n",
    "    return patch_embeddings, patch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the VIT model\n",
    "\n",
    "To load the model we will use the `timm` library.\n",
    "\n",
    "We could also use the `transformers` library and more specific the `ViTForImageClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T17:19:33.057570Z",
     "iopub.status.busy": "2025-01-28T17:19:33.057233Z",
     "iopub.status.idle": "2025-01-28T17:19:33.815386Z",
     "shell.execute_reply": "2025-01-28T17:19:33.814148Z",
     "shell.execute_reply.started": "2025-01-28T17:19:33.057544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    \"vit_tiny_patch16_224\",  # Pre-trained ViT-Tiny on ImageNet-1k\n",
    "    pretrained=True,        # Load pre-trained weights\n",
    "    num_classes=10          # Adapt classifier head to CIFAR-10 (10 classes)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# We dont want to train here so we can freeze all the layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CLS Tokens for the Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:45:59.666182Z",
     "iopub.status.busy": "2025-01-24T17:45:59.665828Z",
     "iopub.status.idle": "2025-01-24T18:09:30.103317Z",
     "shell.execute_reply": "2025-01-24T18:09:30.102260Z",
     "shell.execute_reply.started": "2025-01-24T17:45:59.666156Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating CLS Tokens: 100%|██████████| 704/704 [02:57<00:00,  3.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train_cls_tokens, train_labels = get_dataset_cls_tokens(model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CLS Tokens for the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating CLS Tokens: 100%|██████████| 157/157 [00:47<00:00,  3.33it/s]\n"
     ]
    }
   ],
   "source": [
    "test_cls_tokens, test_labels = get_dataset_cls_tokens(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Patch Embeddings for the Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:20:14.422847Z",
     "iopub.status.busy": "2025-01-28T18:20:14.422387Z",
     "iopub.status.idle": "2025-01-28T18:22:11.593721Z",
     "shell.execute_reply": "2025-01-28T18:22:11.592298Z",
     "shell.execute_reply.started": "2025-01-28T18:20:14.422819Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Patch Embeddings:   0%|          | 0/704 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Patch Embeddings:  10%|▉         | 70/704 [00:41<06:15,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "patch_embeddings, patch_labels = get_dataset_patch_embeddings(model=model, loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:22:37.506656Z",
     "iopub.status.busy": "2025-01-28T18:22:37.506175Z",
     "iopub.status.idle": "2025-01-28T18:22:37.514456Z",
     "shell.execute_reply": "2025-01-28T18:22:37.513003Z",
     "shell.execute_reply.started": "2025-01-28T18:22:37.506616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patch embeddings in memory: 890624\n",
      "Total images in memory: 4544.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Total patch embeddings in memory: {len(patch_embeddings)}')\n",
    "print(f'Total images in memory: {len(patch_embeddings) / 196}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Patch Embeddings for the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:22:45.100886Z",
     "iopub.status.busy": "2025-01-28T18:22:45.100314Z",
     "iopub.status.idle": "2025-01-28T18:24:44.718326Z",
     "shell.execute_reply": "2025-01-28T18:24:44.717152Z",
     "shell.execute_reply.started": "2025-01-28T18:22:45.100850Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Patch Embeddings: 100%|██████████| 157/157 [00:57<00:00,  2.71it/s]\n"
     ]
    }
   ],
   "source": [
    "test_patch_embeddings, test_patch_labels = get_dataset_patch_embeddings(model=model, loader=test_loader, is_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Method: Get Neighbors and Labels\n",
    "\n",
    "This method will be used by other parts of the project. It returns two items:\n",
    "\n",
    "1. `cls_tokens`: An array of shape (num_test, k): Each row contains the cls_token that corresponds the the neighbor.\n",
    "2. `labels`: An array of shape (num_test, k): Each row contains the labels of those top-k images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:24:44.720831Z",
     "iopub.status.busy": "2025-01-28T18:24:44.720493Z",
     "iopub.status.idle": "2025-01-28T18:24:44.730307Z",
     "shell.execute_reply": "2025-01-28T18:24:44.728984Z",
     "shell.execute_reply.started": "2025-01-28T18:24:44.720801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def get_neighbors_and_labels(distance: str, train_data: np.array, train_labels: list, test_data: list, top_k: int = 5):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "    \n",
    "    print(\"Will set labels to cpu\")\n",
    "    clean_labels = []\n",
    "    for label in tqdm(\n",
    "        train_labels, total=len(train_labels), desc=\"Converting labels to cpu\"\n",
    "    ):\n",
    "        clean_labels.append(label.to(\"cpu\"))\n",
    "\n",
    "    # Create a numpy array from the list\n",
    "    print(f\"Total train images: {len(train_data)}\")\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    clean_labels = np.stack(clean_labels, axis=0)\n",
    "    print(f\"Train shape: {train_data.shape}\")\n",
    "    print(f\"Train labels shape: {clean_labels.shape}\")\n",
    "    \n",
    "    # Fit with the train set\n",
    "    knn.fit(train_data)\n",
    "    \n",
    "    # Create a numpy array for the test images\n",
    "    print(f'Total test images: {len(test_data)}')\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f'Test shape: {test_data.shape}')\n",
    "    \n",
    "    # Apply the knn\n",
    "    distances, indexes = knn.kneighbors(test_data, return_distance=True)\n",
    "    \n",
    "    print(f'Distances: {distances.shape}')\n",
    "    print(f'Indexes: {distances.shape}')\n",
    "    \n",
    "    neighbor_labels = []\n",
    "    neighbor_cls_tokens = []\n",
    "    # Gather the final labels\n",
    "    # And the cls_tokens\n",
    "    # For each test image\n",
    "    for i in tqdm(range(indexes.shape[0]), desc='Gathering results'):\n",
    "        # Get the classes of the top_k\n",
    "        classes = clean_labels[indexes[i]]\n",
    "        neighbor_labels.append(classes)\n",
    "        \n",
    "        # Get the cls_tokens of the top_k\n",
    "        cls_tokens = train_data[indexes[i]]\n",
    "        neighbor_cls_tokens.append(cls_tokens)\n",
    "    \n",
    "    # finally convert the the labels to array\n",
    "    neighbor_labels = np.stack(neighbor_labels, axis=0)\n",
    "    # Do the same for the cls\n",
    "    neighbor_cls_tokens = np.stack(neighbor_cls_tokens, axis=0)\n",
    "    \n",
    "    return neighbor_cls_tokens, neighbor_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Method: Get Neighbor Distances and Labels\n",
    "\n",
    "This method will be used by other parts of the project. It returns two items:\n",
    "\n",
    "1. `distances`: An array of shape (num_test, k): Each row contains the distances of the top-k similar images from the train set.\n",
    "2. `labels`: An array of shape (num_test, k): Each row contains the labels of those top-k images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:24:44.732537Z",
     "iopub.status.busy": "2025-01-28T18:24:44.732140Z",
     "iopub.status.idle": "2025-01-28T18:24:44.759106Z",
     "shell.execute_reply": "2025-01-28T18:24:44.757825Z",
     "shell.execute_reply.started": "2025-01-28T18:24:44.732509Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def get_neighbors_distances_and_labels(distance: str, train_data: list, train_labels: np.array, test_data: np.array, top_k: int = 5):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "    \n",
    "    # Create a numpy array from the list\n",
    "    print(f'Total train images: {len(train_data)}')\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    print(f'Train shape: {train_data.shape}')\n",
    "    \n",
    "    # Fit with the train set\n",
    "    knn.fit(train_data)\n",
    "    \n",
    "    # Create a numpy array for the test images\n",
    "    print(f'Total test images: {len(test_data)}')\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f'Test shape: {test_data.shape}')\n",
    "    \n",
    "    # Apply the knn\n",
    "    distances, indexes = knn.kneighbors(test_data, return_distance=True)\n",
    "    \n",
    "    print(f'Distances: {distances.shape}')\n",
    "    print(f'Indexes: {distances.shape}')\n",
    "    \n",
    "    neighbor_labels = []\n",
    "    # Gather the final labels\n",
    "    # For each test image\n",
    "    for i in tqdm(range(indexes.shape[0]), desc='Gathering results'):\n",
    "        # Get the classes of the top_k\n",
    "        classes = train_labels[indexes[i]]\n",
    "        neighbor_labels.append(classes)\n",
    "    \n",
    "    # finally convert the the labels to array\n",
    "    neighbor_labels = np.stack(neighbor_labels, axis=0)\n",
    "\n",
    "    return distances, neighbor_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Method: Get Neighbors and Labels Patch\n",
    "\n",
    "Generate and return __for each patch of a test image__:\n",
    "\n",
    "1. The top_k similar patches from the memory\n",
    "2. The class of each top_k similar patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def get_neigbors_and_labels_patch(\n",
    "    distance: str,\n",
    "    train_data: list,\n",
    "    train_labels: np.array,\n",
    "    test_data: list,\n",
    "    top_k: int = 5,\n",
    "):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "\n",
    "    # Move train_data back to cpu\n",
    "    # train_data = [img.to('cpu') for img in train_data]\n",
    "    print(\"Will set labels to cpu\")\n",
    "    clean_labels = []\n",
    "    for label in tqdm(\n",
    "        train_labels, total=len(train_labels), desc=\"Converting labels to cpu\"\n",
    "    ):\n",
    "        clean_labels.append(label.to(\"cpu\"))\n",
    "\n",
    "    # Create a numpy array from the list\n",
    "    print(f\"Total train images: {len(train_data)}\")\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    train_labels = np.stack(clean_labels, axis=0)\n",
    "    del clean_labels\n",
    "    print(f\"Train shape: {train_data.shape}\")\n",
    "    print(f\"Train labels shape: {train_labels.shape}\")\n",
    "\n",
    "    # Fit with the train set\n",
    "    print(\"Will fit train data to KNN\")\n",
    "    knn.fit(train_data)\n",
    "\n",
    "    # Create a numpy array for the test images\n",
    "    print(f\"Total test images: {len(test_data)}\")\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f\"Test shape: {test_data.shape}\")\n",
    "\n",
    "    neighbor_patches = []\n",
    "    neighbor_classes = []\n",
    "    # For each image\n",
    "    for i in tqdm(range(test_data.shape[0]), desc=\"Gathering results\"):\n",
    "        # Apply the knn for each patch\n",
    "        # Note that the initial test array has a shape of\n",
    "        # (num_test, num_image_patches, hidden_dim)\n",
    "        b_patch_distances, b_patch_indexes = knn.kneighbors(\n",
    "            test_data[i, :, :], return_distance=True\n",
    "        )\n",
    "\n",
    "        # These have a shape of (num_patches, k)\n",
    "\n",
    "        # We now want to find the k classes for each test patch neighbors\n",
    "        b_patch_classes = []\n",
    "        b_patches = []\n",
    "\n",
    "        # Now for each patch we have to get a class\n",
    "        for p in range(b_patch_indexes.shape[0]):\n",
    "            # Get the classes of the top_k\n",
    "            classes = train_labels[b_patch_indexes[p, :]]\n",
    "            # Get the actual patches of the top_k\n",
    "            patches = train_data[b_patch_indexes[p, :]]\n",
    "\n",
    "            b_patch_classes.append(classes)\n",
    "            b_patches.append(patches)\n",
    "\n",
    "        # Now we can add all the neighbor distances and their classes to our final lists\n",
    "        neighbor_patches.append(b_patches)\n",
    "        neighbor_classes.append(b_patch_classes)\n",
    "\n",
    "    # finally convert the lists to arrays\n",
    "    # Again, each list element has a shape of (k,)\n",
    "    # In patch distances it's the distance of each neighbor\n",
    "    # In patch classes it's the class of each neighbor\n",
    "    # Both are with respect to a SINGLE test patch\n",
    "    # neighbor_patches = np.stack(neighbor_patches, axis=0)\n",
    "    # neighbor_classes = np.stack(neighbor_classes, axis=0)\n",
    "\n",
    "    return neighbor_patches, neighbor_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Method: Create .npz files with the test images and the neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_patch_memory(\n",
    "    output_folder: str,\n",
    "    file_name: str,\n",
    "    test_patch,\n",
    "    test_patch_labels,\n",
    "    test_patch_neighbors,\n",
    "    test_patch_neighbor_labels,\n",
    "):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Define the save file path\n",
    "    save_path = os.path.join(output_folder, file_name + \".npz\")\n",
    "\n",
    "    # Save the arrays\n",
    "    np.savez(\n",
    "        save_path,\n",
    "        test_patch=test_patch,\n",
    "        test_labels=test_patch_labels,\n",
    "        neighbor_path=test_patch_neighbors,\n",
    "        neighbor_labels=test_patch_neighbor_labels,\n",
    "    )\n",
    "    print(f\"Data saved successfully to {save_path}\")\n",
    "\n",
    "def save_cls_memory(\n",
    "    output_folder: str,\n",
    "    file_name: str,\n",
    "    test_cls,\n",
    "    test_cls_labels,\n",
    "    test_cls_neighbors,\n",
    "    test_cls_neighbor_labels,\n",
    "):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Define the save file path\n",
    "    save_path = os.path.join(output_folder, file_name + \".npz\")\n",
    "\n",
    "    # Save the arrays\n",
    "    np.savez(\n",
    "        save_path,\n",
    "        test_cls=test_cls,\n",
    "        test_labels=test_cls_labels,\n",
    "        neighbor_cls=test_cls_neighbors,\n",
    "        neighbor_labels=test_cls_neighbor_labels,\n",
    "    )\n",
    "    print(f\"Data saved successfully to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute Force KNN - WITHOUT Test Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CLS Embeddings\n",
    "\n",
    "In the following cells we will try to find the labels from the test images by doing the following:\n",
    "\n",
    "1) Use the `ViT` model to extract the cls_token for the test image\n",
    "2) Find the `topK` similar cls_tokens from the train dataset\n",
    "3) Assign the `y_pred` to the majority class from the KNN\n",
    "\n",
    "__This method will act as our baseline__ as it does not require a finetuned Visual Transformer.\n",
    "\n",
    "The method bellow implements the brute force KNN, using the CLS embeddings for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:24:44.761321Z",
     "iopub.status.busy": "2025-01-28T18:24:44.760929Z",
     "iopub.status.idle": "2025-01-28T18:24:44.785587Z",
     "shell.execute_reply": "2025-01-28T18:24:44.784242Z",
     "shell.execute_reply.started": "2025-01-28T18:24:44.761293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def brute_force_knn(distance: str, train_data: np.array, train_labels: np.array, test_data: np.array, top_k: int = 5):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "    \n",
    "    # Create a numpy array from the list\n",
    "    print(f'Total train images: {len(train_data)}')\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    print(f'Train shape: {train_data.shape}')\n",
    "\n",
    "    # Fit with the train set\n",
    "    knn.fit(train_data)\n",
    "    \n",
    "    # Create a numpy array for the test images\n",
    "    print(f'Total test images: {len(test_data)}')\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f'Test shape: {test_data.shape}')\n",
    "    \n",
    "    # Apply the knn\n",
    "    distances, indexes = knn.kneighbors(test_data, return_distance=True)\n",
    "    \n",
    "    print(f'Distances: {distances.shape}')\n",
    "    print(f'Indexes: {distances.shape}')\n",
    "    \n",
    "    y_pred = []\n",
    "    # Gather the final y_pred\n",
    "    # For each test image\n",
    "    for i in tqdm(range(indexes.shape[0]), desc='Gathering results'):\n",
    "        # Get the classes of the top_k\n",
    "        classes = train_labels[indexes[i]]\n",
    "        # Select the majority as y_pred\n",
    "        y_pred.append(most_common(classes.tolist()))\n",
    "    \n",
    "    # finally convert the y_pred to array\n",
    "    y_pred = np.stack(y_pred, axis=0)\n",
    "\n",
    "    return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T22:50:43.849080Z",
     "iopub.status.busy": "2025-01-21T22:50:43.848583Z",
     "iopub.status.idle": "2025-01-21T22:51:52.473499Z",
     "shell.execute_reply": "2025-01-21T22:51:52.472238Z",
     "shell.execute_reply.started": "2025-01-21T22:50:43.849048Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 3)\n",
      "Indexes: (10000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 185482.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74      1000\n",
      "           1       0.71      0.73      0.72      1000\n",
      "           2       0.77      0.55      0.64      1000\n",
      "           3       0.55      0.49      0.52      1000\n",
      "           4       0.68      0.65      0.66      1000\n",
      "           5       0.60      0.60      0.60      1000\n",
      "           6       0.67      0.83      0.75      1000\n",
      "           7       0.70      0.77      0.74      1000\n",
      "           8       0.79      0.77      0.78      1000\n",
      "           9       0.66      0.76      0.71      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.69      0.69     10000\n",
      "weighted avg       0.69      0.69      0.69     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 5)\n",
      "Indexes: (10000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 284336.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1000\n",
      "           1       0.73      0.75      0.74      1000\n",
      "           2       0.83      0.55      0.66      1000\n",
      "           3       0.58      0.52      0.55      1000\n",
      "           4       0.72      0.67      0.69      1000\n",
      "           5       0.62      0.62      0.62      1000\n",
      "           6       0.67      0.86      0.75      1000\n",
      "           7       0.73      0.78      0.75      1000\n",
      "           8       0.80      0.78      0.79      1000\n",
      "           9       0.67      0.80      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 7)\n",
      "Indexes: (10000, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 84807.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1000\n",
      "           1       0.73      0.76      0.74      1000\n",
      "           2       0.85      0.54      0.66      1000\n",
      "           3       0.59      0.54      0.56      1000\n",
      "           4       0.73      0.67      0.70      1000\n",
      "           5       0.64      0.64      0.64      1000\n",
      "           6       0.66      0.87      0.75      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.82      0.79      0.81      1000\n",
      "           9       0.67      0.81      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 9)\n",
      "Indexes: (10000, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 217921.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1000\n",
      "           1       0.74      0.76      0.75      1000\n",
      "           2       0.86      0.51      0.64      1000\n",
      "           3       0.59      0.54      0.56      1000\n",
      "           4       0.73      0.68      0.71      1000\n",
      "           5       0.64      0.64      0.64      1000\n",
      "           6       0.65      0.88      0.75      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.82      0.79      0.80      1000\n",
      "           9       0.66      0.81      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 11)\n",
      "Indexes: (10000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 131847.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77      1000\n",
      "           1       0.75      0.76      0.75      1000\n",
      "           2       0.88      0.52      0.65      1000\n",
      "           3       0.59      0.54      0.57      1000\n",
      "           4       0.74      0.68      0.70      1000\n",
      "           5       0.65      0.65      0.65      1000\n",
      "           6       0.65      0.88      0.75      1000\n",
      "           7       0.74      0.79      0.76      1000\n",
      "           8       0.82      0.79      0.80      1000\n",
      "           9       0.66      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.71     10000\n",
      "weighted avg       0.73      0.72      0.71     10000\n",
      "\n",
      "Total train images: 45000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 205559.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77      1000\n",
      "           1       0.75      0.76      0.76      1000\n",
      "           2       0.88      0.51      0.65      1000\n",
      "           3       0.60      0.55      0.57      1000\n",
      "           4       0.74      0.68      0.71      1000\n",
      "           5       0.64      0.64      0.64      1000\n",
      "           6       0.65      0.89      0.75      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.82      0.79      0.80      1000\n",
      "           9       0.66      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.71     10000\n",
      "weighted avg       0.73      0.72      0.71     10000\n",
      "\n",
      "Total train images: 45000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 15)\n",
      "Indexes: (10000, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 85766.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77      1000\n",
      "           1       0.75      0.77      0.76      1000\n",
      "           2       0.91      0.50      0.64      1000\n",
      "           3       0.59      0.54      0.56      1000\n",
      "           4       0.73      0.67      0.70      1000\n",
      "           5       0.64      0.65      0.64      1000\n",
      "           6       0.64      0.90      0.75      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.82      0.79      0.81      1000\n",
      "           9       0.66      0.83      0.74      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.71     10000\n",
      "weighted avg       0.73      0.72      0.71     10000\n",
      "\n",
      "Total train images: 45000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 17)\n",
      "Indexes: (10000, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 155206.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1000\n",
      "           1       0.75      0.76      0.76      1000\n",
      "           2       0.91      0.49      0.64      1000\n",
      "           3       0.59      0.55      0.57      1000\n",
      "           4       0.73      0.67      0.70      1000\n",
      "           5       0.66      0.64      0.65      1000\n",
      "           6       0.64      0.90      0.75      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.82      0.79      0.80      1000\n",
      "           9       0.67      0.83      0.74      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.71     10000\n",
      "weighted avg       0.73      0.72      0.71     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 19)\n",
      "Indexes: (10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 89804.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "COSINE - TOP_K: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.77      1000\n",
      "           1       0.74      0.76      0.75      1000\n",
      "           2       0.91      0.49      0.64      1000\n",
      "           3       0.60      0.55      0.57      1000\n",
      "           4       0.74      0.67      0.70      1000\n",
      "           5       0.64      0.64      0.64      1000\n",
      "           6       0.64      0.89      0.74      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.81      0.79      0.80      1000\n",
      "           9       0.66      0.83      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.73      0.71      0.71     10000\n",
      "weighted avg       0.73      0.71      0.71     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# convert the labels to numpy first\n",
    "clean_train_labels = np.stack([label.to('cpu') for label in train_labels], axis=0)\n",
    "clean_test_labels = np.stack([label.to('cpu') for label in test_labels], axis=0)\n",
    "\n",
    "for k in [3, 5, 7, 9, 11, 13, 15, 17, 19]:\n",
    "    y_pred = brute_force_knn(distance=\"cosine\", train_data=train_cls_tokens, train_labels=clean_train_labels, test_data=test_cls_tokens, top_k=k)\n",
    "    print('----------------------------')\n",
    "    print(f'COSINE - TOP_K: {k}')\n",
    "    print(classification_report(clean_test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Euclidian Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T22:53:26.531313Z",
     "iopub.status.busy": "2025-01-21T22:53:26.530905Z",
     "iopub.status.idle": "2025-01-21T22:54:02.469690Z",
     "shell.execute_reply": "2025-01-21T22:54:02.468656Z",
     "shell.execute_reply.started": "2025-01-21T22:53:26.531280Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 3)\n",
      "Indexes: (10000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 183103.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "EUCLIDEAN - TOP_K: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.73      1000\n",
      "           1       0.71      0.70      0.70      1000\n",
      "           2       0.75      0.54      0.63      1000\n",
      "           3       0.53      0.48      0.50      1000\n",
      "           4       0.66      0.66      0.66      1000\n",
      "           5       0.58      0.58      0.58      1000\n",
      "           6       0.68      0.82      0.74      1000\n",
      "           7       0.71      0.75      0.73      1000\n",
      "           8       0.75      0.77      0.76      1000\n",
      "           9       0.65      0.74      0.69      1000\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.68      0.67      0.67     10000\n",
      "weighted avg       0.68      0.67      0.67     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 5)\n",
      "Indexes: (10000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 371466.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "EUCLIDEAN - TOP_K: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74      1000\n",
      "           1       0.74      0.71      0.73      1000\n",
      "           2       0.79      0.52      0.63      1000\n",
      "           3       0.57      0.51      0.54      1000\n",
      "           4       0.69      0.68      0.69      1000\n",
      "           5       0.61      0.62      0.62      1000\n",
      "           6       0.68      0.86      0.76      1000\n",
      "           7       0.73      0.76      0.74      1000\n",
      "           8       0.76      0.78      0.77      1000\n",
      "           9       0.67      0.79      0.72      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.70      0.69     10000\n",
      "weighted avg       0.70      0.70      0.69     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 7)\n",
      "Indexes: (10000, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 357129.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "EUCLIDEAN - TOP_K: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75      1000\n",
      "           1       0.77      0.73      0.75      1000\n",
      "           2       0.83      0.51      0.63      1000\n",
      "           3       0.58      0.53      0.55      1000\n",
      "           4       0.69      0.69      0.69      1000\n",
      "           5       0.63      0.62      0.63      1000\n",
      "           6       0.68      0.87      0.76      1000\n",
      "           7       0.73      0.76      0.74      1000\n",
      "           8       0.77      0.81      0.79      1000\n",
      "           9       0.67      0.81      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 9)\n",
      "Indexes: (10000, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 317396.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "EUCLIDEAN - TOP_K: 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1000\n",
      "           1       0.76      0.73      0.74      1000\n",
      "           2       0.84      0.50      0.63      1000\n",
      "           3       0.59      0.54      0.56      1000\n",
      "           4       0.68      0.69      0.68      1000\n",
      "           5       0.63      0.63      0.63      1000\n",
      "           6       0.67      0.87      0.76      1000\n",
      "           7       0.73      0.76      0.75      1000\n",
      "           8       0.78      0.80      0.79      1000\n",
      "           9       0.67      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 11)\n",
      "Indexes: (10000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 246390.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "EUCLIDEAN - TOP_K: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.76      0.73      0.75      1000\n",
      "           2       0.85      0.49      0.62      1000\n",
      "           3       0.59      0.53      0.56      1000\n",
      "           4       0.68      0.69      0.69      1000\n",
      "           5       0.63      0.63      0.63      1000\n",
      "           6       0.67      0.87      0.75      1000\n",
      "           7       0.74      0.77      0.76      1000\n",
      "           8       0.77      0.80      0.78      1000\n",
      "           9       0.67      0.81      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 171473.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "EUCLIDEAN - TOP_K: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.77      0.73      0.75      1000\n",
      "           2       0.85      0.49      0.62      1000\n",
      "           3       0.59      0.54      0.56      1000\n",
      "           4       0.71      0.69      0.70      1000\n",
      "           5       0.63      0.65      0.64      1000\n",
      "           6       0.65      0.87      0.75      1000\n",
      "           7       0.75      0.77      0.76      1000\n",
      "           8       0.77      0.80      0.78      1000\n",
      "           9       0.66      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.70     10000\n",
      "weighted avg       0.72      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 15)\n",
      "Indexes: (10000, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 297495.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "EUCLIDEAN - TOP_K: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.76      0.72      0.74      1000\n",
      "           2       0.85      0.48      0.61      1000\n",
      "           3       0.58      0.52      0.55      1000\n",
      "           4       0.70      0.68      0.69      1000\n",
      "           5       0.63      0.64      0.63      1000\n",
      "           6       0.65      0.87      0.75      1000\n",
      "           7       0.74      0.77      0.75      1000\n",
      "           8       0.77      0.82      0.79      1000\n",
      "           9       0.66      0.82      0.73      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.70     10000\n",
      "weighted avg       0.71      0.70      0.70     10000\n",
      "\n",
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: (10000, 17)\n",
      "Indexes: (10000, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 108799.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "EUCLIDEAN - TOP_K: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1000\n",
      "           1       0.77      0.71      0.74      1000\n",
      "           2       0.86      0.48      0.62      1000\n",
      "           3       0.59      0.53      0.55      1000\n",
      "           4       0.70      0.68      0.69      1000\n",
      "           5       0.62      0.64      0.63      1000\n",
      "           6       0.65      0.87      0.74      1000\n",
      "           7       0.74      0.76      0.75      1000\n",
      "           8       0.77      0.81      0.79      1000\n",
      "           9       0.66      0.83      0.74      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.70     10000\n",
      "weighted avg       0.71      0.71      0.70     10000\n",
      "\n",
      "Total train images: 45000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (45000, 192)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 19)\n",
      "Indexes: (10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 221297.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "EUCLIDEAN - TOP_K: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76      1000\n",
      "           1       0.77      0.72      0.74      1000\n",
      "           2       0.87      0.46      0.60      1000\n",
      "           3       0.59      0.53      0.56      1000\n",
      "           4       0.69      0.67      0.68      1000\n",
      "           5       0.63      0.66      0.64      1000\n",
      "           6       0.64      0.87      0.74      1000\n",
      "           7       0.75      0.76      0.76      1000\n",
      "           8       0.77      0.81      0.79      1000\n",
      "           9       0.67      0.84      0.74      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.70     10000\n",
      "weighted avg       0.71      0.70      0.70     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# convert the labels to numpy first\n",
    "clean_train_labels = np.stack([label.to('cpu') for label in train_labels], axis=0)\n",
    "clean_test_labels = np.stack([label.to('cpu') for label in test_labels], axis=0)\n",
    "\n",
    "for k in [3, 5, 7, 9, 11, 13, 15, 17, 19]:\n",
    "    y_pred = brute_force_knn(distance=\"euclidean\", train_data=train_cls_tokens, train_labels=clean_train_labels, test_data=test_cls_tokens, top_k=k)\n",
    "    print('----------------------------')\n",
    "    print(f'EUCLIDEAN - TOP_K: {k}')\n",
    "    print(classification_report(clean_test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Patch Embeddings\n",
    "\n",
    "In the following cells we will try to find the labels from the test images by doing the following:\n",
    "\n",
    "1) Use the `ViT` model to extract the patch_embeddings for the test image\n",
    "2) Find the `topK` similar patch embeddings for __each patch of the test image__\n",
    "3) Find a `y_pred` for __each patch of the test image__\n",
    "4) Assign the final y_pred to the majority\n",
    "5) \n",
    "__This method will act as our baseline__ as it does not require a finetuned Visual Transformer.\n",
    "\n",
    "The method bellow implements the brute force KNN, using the CLS embeddings for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:41:31.278043Z",
     "iopub.status.busy": "2025-01-28T18:41:31.277458Z",
     "iopub.status.idle": "2025-01-28T18:41:31.289100Z",
     "shell.execute_reply": "2025-01-28T18:41:31.287229Z",
     "shell.execute_reply.started": "2025-01-28T18:41:31.277992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def patch_brute_force_knn(distance: str, train_data: list, train_labels: np.array, test_data: list, top_k: int = 5):\n",
    "    # Initialize the knn\n",
    "    knn = NearestNeighbors(n_neighbors=top_k, algorithm=\"brute\", metric=distance)\n",
    "    \n",
    "    # Move train_data back to cpu\n",
    "    # train_data = [img.to('cpu') for img in train_data]\n",
    "    print('Will set labels to cpu')\n",
    "    clean_labels = []\n",
    "    for label in tqdm(train_labels, total=len(train_labels), desc=\"Converting labels to cpu\"):\n",
    "        clean_labels.append(label.to('cpu'))\n",
    "\n",
    "    # Create a numpy array from the list\n",
    "    print(f'Total train images: {len(train_data)}')\n",
    "    train_data = np.stack(train_data, axis=0)\n",
    "    clean_labels = np.stack(clean_labels, axis=0)\n",
    "    print(f'Train shape: {train_data.shape}')\n",
    "    print(f'Train labels shape: {clean_labels.shape}')\n",
    "    \n",
    "    # Fit with the train set\n",
    "    print('Will fit train data to KNN')\n",
    "    knn.fit(train_data)\n",
    "    \n",
    "    # Create a numpy array for the test images\n",
    "    print(f'Total test images: {len(test_data)}')\n",
    "    test_data = np.stack(test_data, axis=0)\n",
    "    print(f'Test shape: {test_data.shape}')\n",
    "\n",
    "    y_pred = []\n",
    "    # For each image\n",
    "    for i in tqdm(range(test_data.shape[0]), desc='Gathering results'):\n",
    "        # Apply the knn for each patch\n",
    "        # Note that the initial test array has a shape of\n",
    "        # (num_test, num_image_patches, hidden_dim)\n",
    "        patch_distances, patch_indexes = knn.kneighbors(test_data[i, :, :], return_distance=True)\n",
    "        # print(patch_distances.shape)\n",
    "        # print(patch_indexes.shape)\n",
    "        patch_y_pred = []\n",
    "        # Now for each patch we have to get a class\n",
    "        for p in range(patch_indexes.shape[0]):\n",
    "            # Get the classes of the top_k\n",
    "            # print(patch_indexes[p])\n",
    "            # print(clean_labels[patch_indexes[p]])\n",
    "            classes = clean_labels[patch_indexes[p, :]]\n",
    "            # Select the majority and keep it in the list\n",
    "            # print(most_common(classes.tolist()))\n",
    "            patch_y_pred.append(most_common(classes.tolist()))\n",
    "\n",
    "        # print(patch_y_pred)\n",
    "        # print(len(patch_y_pred))\n",
    "        # Now from the patch_y_pred get the majority as the final class label\n",
    "        y_pred.append(most_common(patch_y_pred))\n",
    "\n",
    "    # finally convert the y_pred to array\n",
    "    y_pred = np.stack(y_pred, axis=0)\n",
    "\n",
    "    return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T18:41:33.243941Z",
     "iopub.status.busy": "2025-01-28T18:41:33.243526Z",
     "iopub.status.idle": "2025-01-28T19:00:05.717247Z",
     "shell.execute_reply": "2025-01-28T19:00:05.716006Z",
     "shell.execute_reply.started": "2025-01-28T18:41:33.243912Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu:   0%|          | 964/890624 [00:00<05:34, 2660.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 890624/890624 [02:22<00:00, 6247.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 890624\n",
      "Train shape: (890624, 192)\n",
      "Train labels shape: (890624,)\n",
      "Will fit train data to KNN\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 196, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [8:34:05<00:00,  3.08s/it]  \n"
     ]
    }
   ],
   "source": [
    "results = patch_brute_force_knn(\"cosine\", patch_embeddings, patch_labels, test_patch_embeddings, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T19:21:19.918011Z",
     "iopub.status.busy": "2025-01-28T19:21:19.917070Z",
     "iopub.status.idle": "2025-01-28T19:21:19.949324Z",
     "shell.execute_reply": "2025-01-28T19:21:19.947766Z",
     "shell.execute_reply.started": "2025-01-28T19:21:19.917961Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72      1010\n",
      "           1       0.80      0.79      0.79      1010\n",
      "           2       0.42      0.85      0.56       491\n",
      "           3       0.46      0.64      0.53       724\n",
      "           4       0.64      0.68      0.66       941\n",
      "           5       0.67      0.64      0.65      1041\n",
      "           6       0.84      0.66      0.74      1286\n",
      "           7       0.78      0.69      0.74      1128\n",
      "           8       0.77      0.81      0.79       949\n",
      "           9       0.88      0.62      0.73      1420\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.71      0.69     10000\n",
      "weighted avg       0.73      0.70      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_patch_labels = [ label[0].to('cpu') for label in test_patch_labels ]\n",
    "\n",
    "print(classification_report(results, test_patch_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 890624/890624 [02:27<00:00, 6051.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 890624\n",
      "Train shape: (890624, 192)\n",
      "Train labels shape: (890624,)\n",
      "Will fit train data to KNN\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 196, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [4:00:38<00:00,  1.44s/it] \n"
     ]
    }
   ],
   "source": [
    "results = patch_brute_force_knn(\"euclidean\", patch_embeddings, patch_labels, test_patch_embeddings, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.74      0.70       885\n",
      "           1       0.78      0.77      0.78      1017\n",
      "           2       0.48      0.80      0.60       606\n",
      "           3       0.43      0.64      0.51       676\n",
      "           4       0.56      0.74      0.63       754\n",
      "           5       0.74      0.62      0.67      1197\n",
      "           6       0.81      0.64      0.71      1271\n",
      "           7       0.78      0.66      0.72      1180\n",
      "           8       0.78      0.78      0.78       991\n",
      "           9       0.90      0.63      0.74      1423\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.70      0.68     10000\n",
      "weighted avg       0.73      0.69      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_patch_labels = [ label[0].to('cpu') for label in test_patch_labels ]\n",
    "\n",
    "print(classification_report(results, test_patch_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Helper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Neighbors and Labels using CLS\n",
    "\n",
    "The following cell performs multiple runs with a different `K` and does the following:\n",
    "\n",
    "1. Calculates the neighbors and labels for each test image, __using the cls representation__\n",
    "\n",
    "2. Saves the neighbor cls tokens, the neighbor labels, the test cls tokens and the test labels into a `.npz` file\n",
    "\n",
    "THose `.npz` files are used in another notebook, to enchance the prediction of a trained Visual Transformer, and to finally calculate the predicted class for each of the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T18:48:51.947741Z",
     "iopub.status.busy": "2025-01-24T18:48:51.947271Z",
     "iopub.status.idle": "2025-01-24T18:48:59.935751Z",
     "shell.execute_reply": "2025-01-24T18:48:59.934650Z",
     "shell.execute_reply.started": "2025-01-24T18:48:51.947671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting test labels to cpu:   7%|▋         | 723/10000 [00:00<00:02, 3714.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting test labels to cpu: 100%|██████████| 10000/10000 [00:02<00:00, 3741.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing k: 3 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:06<00:00, 6823.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 3)\n",
      "Indexes: (10000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 227508.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_3.npz\n",
      "Processing k: 5 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:15<00:00, 2968.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 5)\n",
      "Indexes: (10000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 83647.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_5.npz\n",
      "Processing k: 7 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:12<00:00, 3537.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 7)\n",
      "Indexes: (10000, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 62275.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_7.npz\n",
      "Processing k: 9 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:14<00:00, 3135.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 9)\n",
      "Indexes: (10000, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 61076.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_9.npz\n",
      "Processing k: 11 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:12<00:00, 3723.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 11)\n",
      "Indexes: (10000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 63163.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_11.npz\n",
      "Processing k: 13 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:12<00:00, 3581.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 50723.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_13.npz\n",
      "Processing k: 15 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:13<00:00, 3228.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 15)\n",
      "Indexes: (10000, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 44411.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_15.npz\n",
      "Processing k: 17 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:10<00:00, 4138.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 17)\n",
      "Indexes: (10000, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 60593.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_17.npz\n",
      "Processing k: 19 - Distances: cosine\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:11<00:00, 3803.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 19)\n",
      "Indexes: (10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 36863.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_cosine_19.npz\n",
      "Processing k: 3 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:13<00:00, 3248.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 3)\n",
      "Indexes: (10000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 153114.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_3.npz\n",
      "Processing k: 5 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:11<00:00, 3983.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 5)\n",
      "Indexes: (10000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 105939.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_5.npz\n",
      "Processing k: 7 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:09<00:00, 4747.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 7)\n",
      "Indexes: (10000, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 117148.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_7.npz\n",
      "Processing k: 9 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:10<00:00, 4139.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 9)\n",
      "Indexes: (10000, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 101198.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_9.npz\n",
      "Processing k: 11 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:10<00:00, 4094.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 11)\n",
      "Indexes: (10000, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 53447.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_11.npz\n",
      "Processing k: 13 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:10<00:00, 4264.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 13)\n",
      "Indexes: (10000, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 54808.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_13.npz\n",
      "Processing k: 15 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:09<00:00, 4596.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 15)\n",
      "Indexes: (10000, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 60011.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_15.npz\n",
      "Processing k: 17 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:10<00:00, 4170.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 17)\n",
      "Indexes: (10000, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 62108.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_17.npz\n",
      "Processing k: 19 - Distances: euclidean\n",
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 45000/45000 [00:09<00:00, 4932.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 45000\n",
      "Train shape: (45000, 192)\n",
      "Train labels shape: (45000,)\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 192)\n",
      "Distances: (10000, 19)\n",
      "Indexes: (10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [00:00<00:00, 61543.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to ./cls_neighbors_euclidean_19.npz\n"
     ]
    }
   ],
   "source": [
    "# We want to extract neighbors and classes for the following K\n",
    "K = [3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "# We want each K to be tested with cosine and euclidean\n",
    "distances = [\"cosine\"] * len(K) + [\"euclidean\"] * len(K)\n",
    "# So we have to double the Ks\n",
    "K = K * 2\n",
    "\n",
    "output_folder = \"./\"\n",
    "\n",
    "# Convert the test labels to cpu\n",
    "cpu_test_labels = []\n",
    "for label in tqdm(test_labels, desc='Converting test labels to cpu'):\n",
    "    cpu_test_labels.append(label.to('cpu'))\n",
    "\n",
    "# Now also convert to numpy array\n",
    "cpu_test_labels = np.stack(cpu_test_labels, axis=0)\n",
    "\n",
    "for distance, k in zip(distances, K):\n",
    "    \n",
    "    print(f'Processing k: {k} - Distances: {distance}')\n",
    "\n",
    "    # calculate\n",
    "    neighbor_cls, neighbor_labels = get_neighbors_and_labels(\n",
    "        distance=distance,\n",
    "        train_data=train_cls_tokens,\n",
    "        train_labels=train_labels,\n",
    "        test_data=test_cls_tokens,\n",
    "        top_k=k,\n",
    "    )\n",
    "\n",
    "    file_name = f\"cls_neighbors_{distance}_{k}\"\n",
    "\n",
    "    test_cls_tokens_arr = np.stack(test_cls_tokens, axis=0)\n",
    "\n",
    "    # now save to npz file\n",
    "    save_cls_memory(\n",
    "        output_folder=output_folder,\n",
    "        file_name=file_name,\n",
    "        test_cls=test_cls_tokens_arr,\n",
    "        test_cls_labels=cpu_test_labels,\n",
    "        test_cls_neighbors=neighbor_cls,\n",
    "        test_cls_neighbor_labels=neighbor_labels,\n",
    "    )\n",
    "\n",
    "    # if distance == 'euclidean':\n",
    "        # break\n",
    "\n",
    "\n",
    "# print(f'Neighbor CLS: {neighbor_cls.shape}')\n",
    "# print(f'Neighbor Labels: {neighbor_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Neighbors and Labels using Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors, classes = get_neigbors_and_labels_patch(\n",
    "    \"cosine\", patch_embeddings, patch_labels, test_patch_embeddings, 5\n",
    ")\n",
    "\n",
    "print(f\"Neighbors: {neighbors.shape}\")\n",
    "print(f\"Classes: {classes.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./euclidian_patch_classes.pkl', 'rb') as f:\n",
    "    classes = pickle.load(f)\n",
    "\n",
    "with open('./euclidian_patch_neighbors.pkl', 'rb') as f:\n",
    "    neighbors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors: (10000, 196, 5, 192)\n",
      "Classes: (10000, 196, 5)\n"
     ]
    }
   ],
   "source": [
    "neighbors = np.stack(neighbors, axis=0)\n",
    "classes = np.stack(classes, axis=0)\n",
    "\n",
    "print(f\"Neighbors: {neighbors.shape}\")\n",
    "print(f\"Classes: {classes.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the test labels to cpu and change them to (test_size,)\n",
    "clean_test_labels = []\n",
    "for image in tqdm(test_patch_labels, desc='Converting test labels to cpu'):\n",
    "    # We can do this here as all the patches of a test image have the same label\n",
    "    clean_test_labels.append(image[0].to('cpu'))\n",
    "\n",
    "clean_test_labels = np.stack(clean_test_labels, axis=0)\n",
    "\n",
    "# Convert the patch embeddings to array\n",
    "test_patches = np.stack(test_patch_embeddings, axis=0)\n",
    "\n",
    "print(f'Test patches: {test_patches.shape}')\n",
    "print(f'Test labels: {clean_test_labels.shape}')\n",
    "print(f\"Neighbors: {neighbors.shape}\")\n",
    "print(f\"Classes: {classes.shape}\")\n",
    "\n",
    "save_patch_memory(output_folder='./', file_name='patch_memory', test_patch=test_patches, test_patch_labels=clean_test_labels, test_patch_neighbors=neighbors, test_patch_neighbor_labels=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will set labels to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labels to cpu: 100%|██████████| 890624/890624 [02:05<00:00, 7086.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train images: 890624\n",
      "Train shape: (890624, 192)\n",
      "Train labels shape: (890624,)\n",
      "Will fit train data to KNN\n",
      "Total test images: 10000\n",
      "Test shape: (10000, 196, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering results: 100%|██████████| 10000/10000 [4:20:04<00:00,  1.56s/it] \n"
     ]
    }
   ],
   "source": [
    "neighbors, classes = get_neigbors_and_labels_patch(\n",
    "    \"euclidean\", patch_embeddings, patch_labels, test_patch_embeddings, 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./euclidian_patch_neighbors.pkl', 'wb') as f:\n",
    "    pickle.dump(neighbors, f)\n",
    "\n",
    "with open('./euclidian_patch_classes.pkl', 'wb') as f:\n",
    "    pickle.dump(classes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./euclidian_patch_neighbors.pkl', 'rb') as f:\n",
    "    neighbors = pickle.load(f)\n",
    "\n",
    "with open('./euclidian_patch_classes.pkl', 'rb') as f:\n",
    "    classes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors: (10000, 196, 5, 192)\n",
      "Classes: (10000, 196, 5)\n"
     ]
    }
   ],
   "source": [
    "neighbors = np.stack(neighbors, axis=0)\n",
    "classes = np.stack(classes, axis=0)\n",
    "\n",
    "print(f\"Neighbors: {neighbors.shape}\")\n",
    "print(f\"Classes: {classes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting test labels to cpu: 100%|██████████| 10000/10000 [00:03<00:00, 2863.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test patches: (10000, 196, 192)\n",
      "Test labels: (10000,)\n",
      "Data saved successfully to ./patch_memory_euclidian.npz\n"
     ]
    }
   ],
   "source": [
    "# Convert the test labels to cpu and change them to (test_size,)\n",
    "clean_test_labels = []\n",
    "for image in tqdm(test_patch_labels, desc='Converting test labels to cpu'):\n",
    "    # We can do this here as all the patches of a test image have the same label\n",
    "    clean_test_labels.append(image[0].to('cpu'))\n",
    "\n",
    "clean_test_labels = np.stack(clean_test_labels, axis=0)\n",
    "\n",
    "# Convert the patch embeddings to array\n",
    "test_patches = np.stack(test_patch_embeddings, axis=0)\n",
    "\n",
    "print(f'Test patches: {test_patches.shape}')\n",
    "print(f'Test labels: {clean_test_labels.shape}')\n",
    "# print(f\"Neighbors: {neighbors.shape}\")\n",
    "# print(f\"Classes: {classes.shape}\")\n",
    "\n",
    "save_patch_memory(output_folder='./', file_name='patch_memory_euclidian', test_patch=test_patches, test_patch_labels=clean_test_labels, test_patch_neighbors=neighbors, test_patch_neighbor_labels=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved file to verify the sizes are the expected ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('/home/panos/WSL_projects/rag-enhanced-image-classification/src/development/patch_memory.npz') as data:\n",
    "    tp = data['test_patch']\n",
    "    tl = data['test_labels']\n",
    "    n=data['neighbor_path']\n",
    "    c=data['neighbor_labels']\n",
    "\n",
    "print(f'Test patches: {tp.shape}')\n",
    "print(f'Test labels: {tl.shape}')\n",
    "print(f\"Neighbors: {n.shape}\")\n",
    "print(f\"Classes: {c.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
